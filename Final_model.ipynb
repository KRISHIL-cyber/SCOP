{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Final_model.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RGmPhUJ5MSZW"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import seaborn as sb\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import confusion_matrix, precision_score, accuracy_score, recall_score, f1_score, classification_report\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -U xgboost"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZZfGLdGKMbMb",
        "outputId": "a64d4bce-448d-4652-aa73-48212386f51c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: xgboost in /usr/local/lib/python3.7/dist-packages (0.90)\n",
            "Collecting xgboost\n",
            "  Downloading xgboost-1.5.2-py3-none-manylinux2014_x86_64.whl (173.6 MB)\n",
            "\u001b[K     |████████████████████████████████| 173.6 MB 8.1 kB/s \n",
            "\u001b[?25hRequirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.4.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.7/dist-packages (from xgboost) (1.21.5)\n",
            "Installing collected packages: xgboost\n",
            "  Attempting uninstall: xgboost\n",
            "    Found existing installation: xgboost 0.90\n",
            "    Uninstalling xgboost-0.90:\n",
            "      Successfully uninstalled xgboost-0.90\n",
            "Successfully installed xgboost-1.5.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from xgboost import XGBClassifier"
      ],
      "metadata": {
        "id": "ESOO58knMeca"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ulyxrP9iMh5F",
        "outputId": "789fb58e-7d0c-400c-8931-12049c8dc430"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pickle"
      ],
      "metadata": {
        "id": "WTe8JXVQllds"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "accuracy_scores=[]"
      ],
      "metadata": {
        "id": "cXKW3Jw4Mh1S"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/drive/MyDrive/Project/Features_PSSM"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "00ji0qd5DAMW",
        "outputId": "fe3ccb39-3ca1-47aa-e222-4ecfeb2f8589"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/drive/MyDrive/Project/Features_PSSM\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "def classModel3(data):\n",
        "  X= data.iloc[:,:-1].values\n",
        "  y= data.iloc[:,-1].values\n",
        "  \n",
        "  le = LabelEncoder()\n",
        "  print(y)\n",
        "  y= le.fit_transform(y) \n",
        "  print(y)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 5)\n",
        "\n",
        "  model = XGBClassifier(tree_method='gpu_hist',use_label_encoder=False)\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  print('\\nClassification report:\\n', classification_report(y_test,y_pred))\n",
        "  print('Confusion matrix: \\n', confusion_matrix(y_test,y_pred))\n",
        "\n",
        "  accuracy = accuracy_score(y_test,y_pred)\n",
        "  accuracy_scores.append(accuracy)\n",
        "  print(\"\\n\\nAccuracy:\",accuracy_score(y_test, y_pred))\n",
        "\n",
        "  print(\"\\n\\nPrecision:\",precision_score(y_test, y_pred, average=None))\n",
        "  print(\"\\nRecall:\",recall_score(y_test, y_pred, average=None))\n",
        "  print(\"\\nF1 score:\",f1_score(y_test, y_pred, average=None))"
      ],
      "metadata": {
        "id": "_dAGC1H0FZmP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def automation(filenames):\n",
        "  size= len(filenames)\n",
        "  for i in range(size):\n",
        "    print()\n",
        "    print()\n",
        "    print(\"Feature Name: \", filenames[i])\n",
        "    print()\n",
        "    data = pd.read_csv(filenames[i])\n",
        "    classModel3(data)"
      ],
      "metadata": {
        "id": "tTxIamFBF0ZD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "files= ['AADP_PSSM.csv', 'DPC_PSSM.csv', 'DFMCA_PSSM.csv', 'LPC_PSSM.csv', 'MBMGAC_PSSM.csv',\n",
        "        'SOMA_PSSM.csv', 'SINGLE_AVERAGE_PSSM.csv', 'SVD_PSSM.csv',\n",
        "        'AATP_TPCC.csv',\n",
        "               'K_SEPERATED_BIGRAME.csv',\n",
        "               'CS_PSE_PSSM.csv',\n",
        "               'DWT_PSSM.csv',\n",
        "               'EDP_MEDP.csv',\n",
        "               'FPSSM.csv',\n",
        "               'PSSMBLOCK.csv',\n",
        "               'SCSH2.csv',\n",
        "               'TRIGRAME_PSSM.csv',\n",
        "                'combined_CS_PSE_MBMGAC.csv',\n",
        "        'combined_pssm.csv'\n",
        "               ]"
      ],
      "metadata": {
        "id": "IHa_O-tsHYUc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "automation(files)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BYT3K00pED42",
        "outputId": "26ebe836-eb71-4794-cd2d-70f751d366b6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Feature Name:  AADP_PSSM.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:21:59] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.77      0.79       772\n",
            "           1       0.74      0.77      0.76       825\n",
            "           2       0.84      0.89      0.87      1293\n",
            "           3       0.70      0.63      0.66      1021\n",
            "\n",
            "    accuracy                           0.78      3911\n",
            "   macro avg       0.77      0.77      0.77      3911\n",
            "weighted avg       0.77      0.78      0.78      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 598   33   54   87]\n",
            " [  29  637   38  121]\n",
            " [  27   35 1157   74]\n",
            " [  91  152  130  648]]\n",
            "\n",
            "\n",
            "Accuracy: 0.7772948095116339\n",
            "\n",
            "\n",
            "Precision: [0.80268456 0.74329055 0.83901378 0.69677419]\n",
            "\n",
            "Recall: [0.7746114  0.77212121 0.89481825 0.63467189]\n",
            "\n",
            "F1 score: [0.78839815 0.75743163 0.86601796 0.66427473]\n",
            "\n",
            "\n",
            "Feature Name:  DPC_PSSM.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:22:18] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.76      0.79       772\n",
            "           1       0.76      0.79      0.77       825\n",
            "           2       0.84      0.89      0.86      1293\n",
            "           3       0.70      0.65      0.68      1021\n",
            "\n",
            "    accuracy                           0.78      3911\n",
            "   macro avg       0.78      0.77      0.77      3911\n",
            "weighted avg       0.78      0.78      0.78      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 589   41   52   90]\n",
            " [  28  648   35  114]\n",
            " [  26   31 1154   82]\n",
            " [  84  134  137  666]]\n",
            "\n",
            "\n",
            "Accuracy: 0.7816415239069292\n",
            "\n",
            "\n",
            "Precision: [0.81017882 0.7587822  0.83744557 0.69957983]\n",
            "\n",
            "Recall: [0.76295337 0.78545455 0.89249807 0.65230167]\n",
            "\n",
            "F1 score: [0.78585724 0.77188803 0.86409584 0.67511404]\n",
            "\n",
            "\n",
            "Feature Name:  DFMCA_PSSM.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:22:31] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.79      0.81       772\n",
            "           1       0.74      0.78      0.76       825\n",
            "           2       0.82      0.86      0.84      1293\n",
            "           3       0.65      0.61      0.63      1021\n",
            "\n",
            "    accuracy                           0.76      3911\n",
            "   macro avg       0.76      0.76      0.76      3911\n",
            "weighted avg       0.76      0.76      0.76      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 607   37   30   98]\n",
            " [  22  640   45  118]\n",
            " [  21   41 1115  116]\n",
            " [  86  144  164  627]]\n",
            "\n",
            "\n",
            "Accuracy: 0.7642546663257479\n",
            "\n",
            "\n",
            "Precision: [0.82472826 0.7424594  0.82348597 0.65380605]\n",
            "\n",
            "Recall: [0.78626943 0.77575758 0.86233565 0.61410382]\n",
            "\n",
            "F1 score: [0.80503979 0.75874333 0.84246317 0.63333333]\n",
            "\n",
            "\n",
            "Feature Name:  LPC_PSSM.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:22:40] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.74      0.72      0.73       772\n",
            "           1       0.68      0.71      0.70       825\n",
            "           2       0.80      0.84      0.82      1293\n",
            "           3       0.62      0.56      0.59      1021\n",
            "\n",
            "    accuracy                           0.72      3911\n",
            "   macro avg       0.71      0.71      0.71      3911\n",
            "weighted avg       0.71      0.72      0.71      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 552   45   74  101]\n",
            " [  42  589   41  153]\n",
            " [  49   57 1088   99]\n",
            " [ 106  178  164  573]]\n",
            "\n",
            "\n",
            "Accuracy: 0.7164408079774993\n",
            "\n",
            "\n",
            "Precision: [0.73698264 0.67779056 0.79590344 0.6187905 ]\n",
            "\n",
            "Recall: [0.71502591 0.71393939 0.84145398 0.5612145 ]\n",
            "\n",
            "F1 score: [0.72583826 0.69539551 0.81804511 0.58859784]\n",
            "\n",
            "\n",
            "Feature Name:  MBMGAC_PSSM.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:22:53] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.85      0.87       772\n",
            "           1       0.79      0.84      0.82       825\n",
            "           2       0.88      0.90      0.89      1293\n",
            "           3       0.75      0.72      0.73      1021\n",
            "\n",
            "    accuracy                           0.83      3911\n",
            "   macro avg       0.83      0.83      0.83      3911\n",
            "weighted avg       0.83      0.83      0.83      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 656   21   29   66]\n",
            " [  16  697   18   94]\n",
            " [  12   39 1158   84]\n",
            " [  49  127  113  732]]\n",
            "\n",
            "\n",
            "Accuracy: 0.8291996931731015\n",
            "\n",
            "\n",
            "Precision: [0.89495225 0.78846154 0.87860395 0.75      ]\n",
            "\n",
            "Recall: [0.84974093 0.84484848 0.89559165 0.71694417]\n",
            "\n",
            "F1 score: [0.8717608  0.81568169 0.88701647 0.73309965]\n",
            "\n",
            "\n",
            "Feature Name:  SOMA_PSSM.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:23:09] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.82      0.80      0.81       772\n",
            "           1       0.74      0.77      0.75       825\n",
            "           2       0.81      0.85      0.83      1293\n",
            "           3       0.65      0.59      0.62      1021\n",
            "\n",
            "    accuracy                           0.76      3911\n",
            "   macro avg       0.75      0.76      0.75      3911\n",
            "weighted avg       0.75      0.76      0.76      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 620   34   34   84]\n",
            " [  27  638   44  116]\n",
            " [  25   44 1098  126]\n",
            " [  85  152  177  607]]\n",
            "\n",
            "\n",
            "Accuracy: 0.7576067501917668\n",
            "\n",
            "\n",
            "Precision: [0.81902246 0.73502304 0.81152993 0.6505895 ]\n",
            "\n",
            "Recall: [0.80310881 0.77333333 0.84918794 0.59451518]\n",
            "\n",
            "F1 score: [0.81098757 0.75369167 0.82993197 0.62128966]\n",
            "\n",
            "\n",
            "Feature Name:  SINGLE_AVERAGE_PSSM.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:23:17] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.71      0.55      0.62       772\n",
            "           1       0.61      0.64      0.62       825\n",
            "           2       0.71      0.83      0.77      1293\n",
            "           3       0.51      0.48      0.49      1021\n",
            "\n",
            "    accuracy                           0.64      3911\n",
            "   macro avg       0.64      0.62      0.62      3911\n",
            "weighted avg       0.64      0.64      0.63      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 423   95  108  146]\n",
            " [  45  524   79  177]\n",
            " [  26   55 1070  142]\n",
            " [ 103  187  245  486]]\n",
            "\n",
            "\n",
            "Accuracy: 0.639989772436717\n",
            "\n",
            "\n",
            "Precision: [0.70854271 0.60859466 0.71238349 0.51104101]\n",
            "\n",
            "Recall: [0.54792746 0.63515152 0.82753287 0.47600392]\n",
            "\n",
            "F1 score: [0.61796932 0.62158956 0.76565295 0.49290061]\n",
            "\n",
            "\n",
            "Feature Name:  SVD_PSSM.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:23:29] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.55      0.43      0.48       772\n",
            "           1       0.53      0.53      0.53       825\n",
            "           2       0.69      0.80      0.74      1293\n",
            "           3       0.47      0.45      0.46      1021\n",
            "\n",
            "    accuracy                           0.58      3911\n",
            "   macro avg       0.56      0.55      0.55      3911\n",
            "weighted avg       0.57      0.58      0.57      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 332  132  125  183]\n",
            " [ 104  435  103  183]\n",
            " [  35   70 1040  148]\n",
            " [ 136  185  245  455]]\n",
            "\n",
            "\n",
            "Accuracy: 0.5783687036563538\n",
            "\n",
            "\n",
            "Precision: [0.54695222 0.52919708 0.68737607 0.46955624]\n",
            "\n",
            "Recall: [0.43005181 0.52727273 0.80433101 0.44564153]\n",
            "\n",
            "F1 score: [0.48150834 0.52823315 0.74126871 0.45728643]\n",
            "\n",
            "\n",
            "Feature Name:  AATP_TPCC.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:23:33] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.81      0.79      0.80       772\n",
            "           1       0.74      0.82      0.78       825\n",
            "           2       0.86      0.89      0.88      1293\n",
            "           3       0.73      0.65      0.69      1021\n",
            "\n",
            "    accuracy                           0.79      3911\n",
            "   macro avg       0.79      0.79      0.78      3911\n",
            "weighted avg       0.79      0.79      0.79      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 609   41   35   87]\n",
            " [  26  673   29   97]\n",
            " [  29   42 1155   67]\n",
            " [  87  150  121  663]]\n",
            "\n",
            "\n",
            "Accuracy: 0.7926361544362056\n",
            "\n",
            "\n",
            "Precision: [0.81091877 0.74282561 0.8619403  0.72538293]\n",
            "\n",
            "Recall: [0.7888601  0.81575758 0.89327146 0.64936337]\n",
            "\n",
            "F1 score: [0.79973736 0.77758521 0.87732624 0.68527132]\n",
            "\n",
            "\n",
            "Feature Name:  K_SEPERATED_BIGRAME.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:23:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.78      0.71      0.74       772\n",
            "           1       0.70      0.74      0.72       825\n",
            "           2       0.81      0.84      0.82      1293\n",
            "           3       0.63      0.61      0.62      1021\n",
            "\n",
            "    accuracy                           0.73      3911\n",
            "   macro avg       0.73      0.72      0.72      3911\n",
            "weighted avg       0.73      0.73      0.73      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 545   60   68   99]\n",
            " [  34  611   39  141]\n",
            " [  29   51 1088  125]\n",
            " [  95  153  154  619]]\n",
            "\n",
            "\n",
            "Accuracy: 0.7320378419841472\n",
            "\n",
            "\n",
            "Precision: [0.77524893 0.69828571 0.80652335 0.62906504]\n",
            "\n",
            "Recall: [0.70595855 0.74060606 0.84145398 0.60626836]\n",
            "\n",
            "F1 score: [0.73898305 0.71882353 0.82361847 0.61745636]\n",
            "\n",
            "\n",
            "Feature Name:  CS_PSE_PSSM.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:24:02] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.87       772\n",
            "           1       0.81      0.86      0.83       825\n",
            "           2       0.88      0.90      0.89      1293\n",
            "           3       0.77      0.71      0.74      1021\n",
            "\n",
            "    accuracy                           0.84      3911\n",
            "   macro avg       0.83      0.84      0.83      3911\n",
            "weighted avg       0.84      0.84      0.84      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 670   15   27   60]\n",
            " [  14  709   15   87]\n",
            " [  20   32 1164   77]\n",
            " [  56  124  111  730]]\n",
            "\n",
            "\n",
            "Accuracy: 0.8368703656353874\n",
            "\n",
            "\n",
            "Precision: [0.88157895 0.80568182 0.88382688 0.76519916]\n",
            "\n",
            "Recall: [0.86787565 0.85939394 0.90023202 0.71498531]\n",
            "\n",
            "F1 score: [0.87467363 0.83167155 0.89195402 0.73924051]\n",
            "\n",
            "\n",
            "Feature Name:  DWT_PSSM.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:24:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.75      0.77       772\n",
            "           1       0.72      0.74      0.73       825\n",
            "           2       0.80      0.85      0.82      1293\n",
            "           3       0.62      0.58      0.60      1021\n",
            "\n",
            "    accuracy                           0.74      3911\n",
            "   macro avg       0.73      0.73      0.73      3911\n",
            "weighted avg       0.73      0.74      0.74      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 582   46   51   93]\n",
            " [  33  607   46  139]\n",
            " [  25   41 1101  126]\n",
            " [  94  149  183  595]]\n",
            "\n",
            "\n",
            "Accuracy: 0.7376630017898236\n",
            "\n",
            "\n",
            "Precision: [0.79291553 0.72004745 0.79724837 0.62434418]\n",
            "\n",
            "Recall: [0.75388601 0.73575758 0.85150812 0.582762  ]\n",
            "\n",
            "F1 score: [0.77290837 0.72781775 0.82348542 0.60283688]\n",
            "\n",
            "\n",
            "Feature Name:  EDP_MEDP.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:24:28] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.84      0.84       772\n",
            "           1       0.78      0.82      0.80       825\n",
            "           2       0.86      0.89      0.87      1293\n",
            "           3       0.73      0.67      0.70      1021\n",
            "\n",
            "    accuracy                           0.81      3911\n",
            "   macro avg       0.80      0.81      0.80      3911\n",
            "weighted avg       0.81      0.81      0.81      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 646   24   28   74]\n",
            " [  13  680   33   99]\n",
            " [  27   30 1155   81]\n",
            " [  71  135  134  681]]\n",
            "\n",
            "\n",
            "Accuracy: 0.8084888775249297\n",
            "\n",
            "\n",
            "Precision: [0.85336856 0.78250863 0.85555556 0.72834225]\n",
            "\n",
            "Recall: [0.83678756 0.82424242 0.89327146 0.66699314]\n",
            "\n",
            "F1 score: [0.84499673 0.80283353 0.87400681 0.69631902]\n",
            "\n",
            "\n",
            "Feature Name:  FPSSM.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:24:42] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.79      0.76      0.77       772\n",
            "           1       0.73      0.71      0.72       825\n",
            "           2       0.77      0.85      0.81      1293\n",
            "           3       0.62      0.58      0.60      1021\n",
            "\n",
            "    accuracy                           0.73      3911\n",
            "   macro avg       0.73      0.72      0.73      3911\n",
            "weighted avg       0.73      0.73      0.73      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 584   36   63   89]\n",
            " [  33  585   58  149]\n",
            " [  32   36 1100  125]\n",
            " [  89  141  203  588]]\n",
            "\n",
            "\n",
            "Accuracy: 0.7305037074916901\n",
            "\n",
            "\n",
            "Precision: [0.79132791 0.73308271 0.77247191 0.61829653]\n",
            "\n",
            "Recall: [0.75647668 0.70909091 0.85073473 0.57590597]\n",
            "\n",
            "F1 score: [0.77350993 0.72088725 0.8097166  0.59634888]\n",
            "\n",
            "\n",
            "Feature Name:  PSSMBLOCK.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:24:54] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.80      0.74      0.77       772\n",
            "           1       0.72      0.74      0.73       825\n",
            "           2       0.83      0.87      0.85      1293\n",
            "           3       0.68      0.66      0.67      1021\n",
            "\n",
            "    accuracy                           0.76      3911\n",
            "   macro avg       0.76      0.75      0.75      3911\n",
            "weighted avg       0.76      0.76      0.76      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 570   57   49   96]\n",
            " [  36  608   50  131]\n",
            " [  18   51 1127   97]\n",
            " [  89  123  132  677]]\n",
            "\n",
            "\n",
            "Accuracy: 0.7624648427512145\n",
            "\n",
            "\n",
            "Precision: [0.79943899 0.72467223 0.82989691 0.67632368]\n",
            "\n",
            "Recall: [0.73834197 0.7369697  0.8716164  0.66307542]\n",
            "\n",
            "F1 score: [0.76767677 0.73076923 0.85024519 0.66963403]\n",
            "\n",
            "\n",
            "Feature Name:  SCSH2.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:25:05] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.68      0.62      0.65       772\n",
            "           1       0.67      0.62      0.64       825\n",
            "           2       0.70      0.82      0.76      1293\n",
            "           3       0.52      0.47      0.49      1021\n",
            "\n",
            "    accuracy                           0.65      3911\n",
            "   macro avg       0.64      0.63      0.64      3911\n",
            "weighted avg       0.64      0.65      0.64      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 481   43  110  138]\n",
            " [  41  515  106  163]\n",
            " [  53   44 1064  132]\n",
            " [ 128  172  244  477]]\n",
            "\n",
            "\n",
            "Accuracy: 0.6486832012273076\n",
            "\n",
            "\n",
            "Precision: [0.68421053 0.66537468 0.69816273 0.52417582]\n",
            "\n",
            "Recall: [0.62305699 0.62424242 0.8228925  0.46718903]\n",
            "\n",
            "F1 score: [0.65220339 0.6441526  0.75541356 0.49404454]\n",
            "\n",
            "\n",
            "Feature Name:  TRIGRAME_PSSM.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:25:52] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.83      0.81      0.82       772\n",
            "           1       0.79      0.84      0.81       825\n",
            "           2       0.85      0.88      0.86      1293\n",
            "           3       0.72      0.65      0.68      1021\n",
            "\n",
            "    accuracy                           0.80      3911\n",
            "   macro avg       0.80      0.80      0.80      3911\n",
            "weighted avg       0.80      0.80      0.80      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 629   22   46   75]\n",
            " [  15  694   26   90]\n",
            " [  33   28 1137   95]\n",
            " [  84  136  134  667]]\n",
            "\n",
            "\n",
            "Accuracy: 0.7995397596522629\n",
            "\n",
            "\n",
            "Precision: [0.82654402 0.78863636 0.84661206 0.71952535]\n",
            "\n",
            "Recall: [0.81476684 0.84121212 0.87935035 0.6532811 ]\n",
            "\n",
            "F1 score: [0.82061318 0.81407625 0.86267071 0.68480493]\n",
            "\n",
            "\n",
            "Feature Name:  combined_CS_PSE_MBMGAC.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:28:45] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.88      0.88       772\n",
            "           1       0.81      0.87      0.84       825\n",
            "           2       0.90      0.90      0.90      1293\n",
            "           3       0.78      0.74      0.76      1021\n",
            "\n",
            "    accuracy                           0.85      3911\n",
            "   macro avg       0.84      0.85      0.85      3911\n",
            "weighted avg       0.85      0.85      0.85      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 681   10   25   56]\n",
            " [  10  721   13   81]\n",
            " [  19   34 1162   78]\n",
            " [  60  120   90  751]]\n",
            "\n",
            "\n",
            "Accuracy: 0.8476093070825875\n",
            "\n",
            "\n",
            "Precision: [0.88441558 0.81468927 0.90077519 0.77743271]\n",
            "\n",
            "Recall: [0.88212435 0.87393939 0.89868523 0.73555338]\n",
            "\n",
            "F1 score: [0.88326848 0.84327485 0.899729   0.75591344]\n",
            "\n",
            "\n",
            "Feature Name:  combined_pssm.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[06:30:22] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.89      0.89       772\n",
            "           1       0.84      0.89      0.86       825\n",
            "           2       0.92      0.91      0.91      1293\n",
            "           3       0.79      0.76      0.77      1021\n",
            "\n",
            "    accuracy                           0.86      3911\n",
            "   macro avg       0.86      0.86      0.86      3911\n",
            "weighted avg       0.86      0.86      0.86      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 686    9   20   57]\n",
            " [  13  732    7   73]\n",
            " [  15   22 1175   81]\n",
            " [  52  111   81  777]]\n",
            "\n",
            "\n",
            "Accuracy: 0.8616722065967783\n",
            "\n",
            "\n",
            "Precision: [0.89556136 0.8375286  0.91582229 0.78643725]\n",
            "\n",
            "Recall: [0.88860104 0.88727273 0.90873937 0.76101861]\n",
            "\n",
            "F1 score: [0.89206762 0.86168334 0.91226708 0.77351916]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt"
      ],
      "metadata": {
        "id": "nyQvrT8fMVPK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plt.bar(files, accuracy_scores, color ='orange',width = 0.2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "4LXe2zi8IY3H",
        "outputId": "eb20d148-4347-41ea-b6dc-9588da5b0a26"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<BarContainer object of 19 artists>"
            ]
          },
          "metadata": {},
          "execution_count": 13
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.plot(files,accuracy_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "jNYTmMfaIaP2",
        "outputId": "76835091-c2e6-4be5-db65-14b753e5a3cb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7fd667b430d0>]"
            ]
          },
          "metadata": {},
          "execution_count": 14
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAAaoAAAD5CAYAAAB24nEbAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAgAElEQVR4nOy9d3hcx3Ww/w4Wjei9gyRIgp0AKVKkZFm2LIkUZUmWuymnOF8clzgukkvi5MtnO7Lzxb8viUtsWY7suCW2imXHUbWK1TtBCawSSRAkiEb0XdQFdrHz+2NmiRUIEgtgG3bP+zx4AMydO/fce+fOmTNz5ozSWiMIgiAIsUpStAUQBEEQhAshikoQBEGIaURRCYIgCDGNKCpBEAQhphFFJQiCIMQ0ydEWYDpFRUV6+fLl0RZDEARhUbFv375erXVxtOUIBzGnqJYvX05DQ0O0xRAEQVhUKKVaoi1DuJChP0EQBCGmEUUlCIIgxDSiqARBEISYRhSVIAiCENOIohIEQRBiGlFUgiAIQkwjikoQBEGIaURRCYIgxAD7Wvr5/aHOaIsRk8Tcgl9BEIREotM1xjcffoP/aexgbVk212woQykVbbFiClFUgiAIUcDtmeRHzzTzg6dOMKk1n7lyFX95xUpRUjMgikoQBCGCaK35/aEz/ONDr9M2MMa1G8v4u3euo7ogI9qixSyiqARBECLE652D3Hr/EV5s7mNNaTa/+osdvGVVUbTFinlEUQmCIISZgZEJvvXYMX75cgs5S1L4+o0buGn7UpId4s8WDEEpKqXUbuC7gAP4sdb6m9OOLwV+DuTZPF/WWj+klFoOvA4ctVlf0lp/MjSiC4IgxDbeSR+/fPk033rsGMPjXv7kkmXcsnM1eRmp0RZtUTGrolJKOYDbgJ1AG7BXKXWf1vpIQLa/B+7RWt+ulFoPPAQst8dOaK03h1ZsQRCE2Ob5pl7+4f7DHOsa5rJVhXzl+g2sKcuOtliLkmAsqu1Ak9a6GUApdRdwIxCoqDSQY//OBTpCKaQgCMJi4XTfKP/40BEeOdxFdcES/v1PtrJrfal48y2AYBRVJdAa8H8bsGNanq8BjyqlPgNkAlcHHKtRSr0GDAJ/r7V+dvoFlFIfBz4OsHTp0qCFFwRBiBVGxr3c9mQTP372JMkOxZeuWcNH31pDeooj2qItekLlTHET8DOt9b8qpS4F/lMptRHoBJZqrfuUUluB3ymlNmitBwNP1lrfAdwBsG3bNh0imQRBECLCC0293HJPI12D47xnSyV/s3stZbnp0RYrbghGUbUD1QH/V9m0QD4K7AbQWr+olEoHirTW3cC4Td+nlDoBrAZkr3lBEOKCCa+PL917gIzUZH7zl1vZuiw/2iLFHcH4Ru4FapVSNUqpVGAPcN+0PKeBqwCUUuuAdKBHKVVsnTFQSq0AaoHmUAkvCIIQbX69r5V25xhfvWG9KKkwMatFpbX2KqU+DTyCcT3/idb6sFLqVqBBa30f8AXgR0qpWzCOFX+mtdZKqbcBtyqlPIAP+KTWuj9sdyMIghBBxr2T3PZEE1uW5vH21cXRFiduCWqOSmv9EMblPDDtKwF/HwEum+G83wC/WaCMgiAIMck9DW10uNx883114tUXRmRZtCAIwjwY907ygyeb2Losn8trJQxSOBFFJQiCMA/u3ttKp8vNLVevFmsqzIiiEoQI4pn0obWswFjsuD2T3PZkExcvz+eyVYXRFifuEUUlCBFiwuvjsm8+wU+ePxVtUYQFctcrp+kaHBdrKkKIohKECHG4w0X30DiPH+mKtijCAnB7JvnBUyfYXlPApSvFmooEoqgEIULsaxkA4NXTA0x4fVGWRpgvv3r5NN1DYk1FElFUghAhGk4ZRTXu9XGgzRllaYT5MDYxye1Pn+CSFWJNRRJRVIIQAbTWNLQMnF0U+vJJWfe+GPnlyy30WGtKiByiqOKUQ+0uvvybA3gnZYgpFjjdP0rv8Di7NpRSW5IlimoRMjrh5YdPn+AtKwvZsUKsqUgiiipOuaehlbv2tvJSszSIscBeO+y3bVkBO1YUsO9Uv3QiFhn/9VILvcMT3LJTrKlII4oqTmlsNXMgDxyQPSxjgX0t/eSkJ1NbksX2mkJGJiY53DE4+4lCTDA64eXfn27m8toiLl5eEG1xEg5RVHGI2zPJ652DKAW/P3wGj/Tco07DqQEuWpZPUpJiR41p6F6R4b9Fwy9ebKFvZIKbZW4qKoiiikMOdwzimdS876IqnKMenm/qjbZICY1zdILj3cNss1tAlOaks7wwg5dP9kVZMiEYRsa93PFMM29bXSzbeEQJUVRxiH/Y73NX1ZKdlswDBzqjLFFi8+ppMz+1ddnUkNGOmkJeOdmPzyfhlGKdn794iv6RCW65ujbaoiQsoqjikMZWJ+W56VQXZLBzQymPHD7DuHcy2mIlLHtPDZCcpNhcnXc2bXtNAYNuL2+cGYqiZMJsDFtr6oo1xWxZKtZUtBBFFYc0tg6cbRRvqKtgyO3lueMy/Bct9p0aYENlLktSHWfTdqzwz1PJ8F8s8/MXTuEc9cjcVJQRRRVn9A2P09o/dlZRXbaqiNwlKTL8FyUmvD72tznPzk/5qcrPoDJviaynimGG3B7ueKaZK9eWvMkaFiKPKKo4wz8/5f+wUpOTuGZDKY8d6cLtkeG/SHOow8W413eOogLYUVPAKyf7ZduPGOVnz5/CNebhZpmbijqiqOKMxlYnjiTFpqrcs2nX11UwPO7l6WM9UZQsMdlnF/puXT6DolpRQN/IBCd6hiMtljALg24PP3q2mavXlVBXJdZUtBFFFWc0tjpZXZpNRmry2bRLVxaSnyHDf9GgoaWfpQUZlGSnn3Nse40JwyPRQ2KPnz53ikG3V+amYgRRVHGEz6dpbHWeM56e4khi98Zy/vB6F2MTMvwXKbTWNJwaYNsM1hTA8sIMSrLTZOFvjOEa8/Dj55rZub6UjZW5s58ghB1RVHFEc+8IQ24vW2aY+L2hrpzRiUmePNodBckSk1N9o/SNTLBt2cwhd5RSbK8p4OWTfTJPFUP8x3MnGXJ7ZW4qhhBFFUecdaRYeq6i2l5TQFFWqsT+iyANp4yldD6LCmDHikK6Bsc53T8aKbEAE11fFhufi2vUw0+fO8k1G0rZUCHWVKwgiiqOaGwdICstmZXFWeccS3Ykce3Gcp54o5uRcW8UpEs89rUMkJOezKoZ3ocff9y/lyM4T7WvpZ/rv/cc//1ae8SuuVj48XPNDI3L3FSsIYoqjmhsdVJXlYsjaebtsa+vK8ft8fGHN2T4LxI0tAyw1QaiPR+1JVkUZKZGdD3V/zQaq/r3h89E7JqLAefoBD99/hTXbixjXXlOtMURAhBFFSe4PZO80Tl0wYWJ25YXUJKdxgP7Zfgv3AyMTNDUPcy2WbaEUEpx8fL8iAWo9U76eOig8f589niPONcE8KNnmxke9/I5mZuKOYJSVEqp3Uqpo0qpJqXUl2c4vlQp9aRS6jWl1AGl1DsDjv2tPe+oUuqaUAovTHGo3YXXpy+oqBxJinduKuepYz0MuT0RlC7x2Nfi3yhx9vhwO2oKaRsYo905Fm6xePlkP73DE/zxJUtxe3w8e1zW1gH0j0zws+dPcd2mctaWiTUVa8yqqJRSDuA24FpgPXCTUmr9tGx/D9yjtd4C7AF+YM9db//fAOwGfmDLE0LMhRwpArmhvpwJr4/HX++KhFgJS0PLACkORX0QoXciGffv/v0dZKY6+Jvda8lJT+bRI1IPwFhTo55JsaZilGAsqu1Ak9a6WWs9AdwF3Dgtjwb83ZBcwD+2dCNwl9Z6XGt9Emiy5Qkh5rVWJ5V5S2ZcWBrIlup8ynPTeWC/LP4NJ/ta+tlQkUt6yuz9srVlOWSnJ4d9PdWE18fDh86wc30p2ekpXLm2hD+83oU3wTfW7Bse5+cvnOL6ugpWl2ZHWxxhBoJRVJVAa8D/bTYtkK8Bf6yUagMeAj4zh3NRSn1cKdWglGro6ZGhiPnQePrchb4zkZSkuG5TOc8c78E1KsN/4WDcO8n+NldQw35ghmS3Ly8Iu+ff8029uMY83FBfAcCuDWUMjHrODlMmKne+cpoxzySfu2pVtEURzkOonCluAn6mta4C3gn8p1Iq6LK11ndorbdprbcVFxeHSKTEoWdonHbnWNARnq+vr8AzqXn0iHh9hYND7YNMeH0XXD81ne01BTT3jtA95A6bXPfv7yAnPZnLa8039rbVxaQ6khJ++O9gu4uaokxWlYg1FasEo0zageqA/6tsWiAfBe4B0Fq/CKQDRUGeKyyQYOen/NRX5VKVv0Ri/4UJ/0LfreeJSDETO1aYuH/hGv5zeyZ59EgXuzeWkZpsPvustGQuW1XIY0e6EjoyRlP38AXXugnRJxhFtReoVUrVKKVSMc4R903Lcxq4CkAptQ6jqHpsvj1KqTSlVA1QC7wSKuEFQ2PrAI4kxcYgV9Irpbiurpznm3oZGJkIs3SJR0PLAMsLMyjOTgv6nA0VOWSkOsKmqJ462sPwuPfssJ+fnevLON0/ytGuxNxpeMLro6VvlFUloqhimVkVldbaC3waeAR4HePdd1gpdatS6l022xeAjyml9gN3An+mDYcxltYR4PfAX2mtZeFGiGlsdbK2LPtNO8jOxg11FXh9mkcSZNFn/8gEgxFwydda82rLwJysKTCBg7cuyw/bPNX9BzoozEzlUmu5+bl6fQlKwWOHE3P4r6VvBK9Pi6KKcYKaR9JaP6S1Xq21Xqm1/keb9hWt9X327yNa68u01vVa681a60cDzv1He94arfXD4bmNxMXn0xxodc15B9INFTksK8xImOG/j/2igU/916thv87J3hETiHYO81N+dtQUcLRriP4QW7mjE16eeL2bazeVkex48ydfkp3O5uq8hJ2nauo2e4GJooptJDLFIudEzzBD4945KyqlFNfXlfPCiV56h8fDJF3s0NQ9zHNNvTSHeZPChjks9J2Of55q76nQWlWPv97NmGeS6+sqZjy+a30ZB9tddERgwXGs4VdUM8XHFGIHUVSLnNesI8WWIB0pArm+rgKfht8fiu/hv9EJL64xM+x3197WWXIvjIZT/eQuSZlXw1dXlUtaclLIh/8e2N9BaU4aF58nnNPO9aUACbkIvKlnmMq8JWSmJc+eWYgaoqgWOY2tTrLTk1lRNPeGcW1ZNiuKM+N+648Op3H5zkx1cO++Nsa94ZsmDSYQ7flIS3awZWker5wKXYSKQbeHp472cN2mivMGK15VksWK4kweTcB5qqbuYVbKsF/MI4pqkdN42kl9Vd68GkYz/FfByyf76R4M3/qdaNPpMkNa/+uyGvpHJngkTA1y/8gEzT0j85qf8rOjppAjHYMhc/x49HAXE5M+rq8vv2C+XevLeKm576zlmQj4fJoTPeKavhgQRbWIGZuY5GjXhSOmz8b1deVoDQ/H8fBfp7Wo3r+1iuqCJdz58umwXGcqEO3cPP4C2VFTgE/DvlOhiRbxwIEOKvOWzLjrcyA715fi9WmeSqAdoNudY7g9PnGkWASIolrEHGx3MTlLxPTZWF2azerSrLge/uuwFlV5Xjp7Ll7Ki819YXGqaGjpJ8WhqKua/86wW5bmk+JQvBSCALUDIxM8d7yX6+vLUerCFveW6jyKstISyvuvqUc8/hYLoqgwk+2NrU7ueuU033r0KC19I9EWKSgaW02vO9iIFOfj+roK9p4aODtEFm90Ot0UZaWRluzgA9uqSE5SYXGq2HdqgI2VwQWiPR9LUh3UVeWFZOHv7w+fwevT3HAeb79AkpIUO9eX8NQb3WGdw4slTohr+qIhoVxdfD5N68Aor3cO8caZQd6wv1v6RwmMIPMfz53k1hs38t6LKmftiUaTxlYnVflLKMoKPgLCTFxXV863HjvGQwfP8NG31oRIutihwzVGRZ6JKl+Snc7O9aXcu6+NL+xaTVpyaHadcXsmOdDm4iNvWbbgsnbUFHDHM82MTnjJSJ3/J3r//g5WFGWyoSK4/ZV2rS/jzldaefFEH1esKZn3dRcLx7uGKchMpSAzNdqiCLMQt4rKNerhjTODHO0aOquYjp4ZYtTuaKoU1BRmsr4ih/deVMWasmzWleWQlASfv2c/X/j1fp4+1sM33rORnPSUKN/NzDSednLRPNbrTGdlcRbrynN44EBHXCqqTpeblcWZZ/+/aftSHj50hkcOd/Gu+tmtjWA41O5iYtI354gUM7G9poAfPHWCV1ucvLW2aF5ldA+5eam5j0+/Y1XQna1LVxaSkerg0SNdCaGomsSRYtEQN4rKOTrBHc8088aZId7oHKTDNeXFlpeRwtqybD64rZp15dmsLcuhtjTrvL3VOz92Cbc/1cS3Hz/Oq6cH+O6ezSFpgEJJ96CbDpebP1/A/FQg19eV88+PHKVtYJSq/IyQlBkLaK3pdI7x1lVTDf5bVxWddaoIlaI6u9B3AR5/frYtLyBJwcsn++atqB4+eAaf5pzYfhciPcXBFWuKefxIF9+4ceO8PEkXC1prmrqHua7uwt6QQmwQN4oq2ZHEj589SU1RJhfXFLC2LIe15cZKKs1Jm9MQniNJ8ekra3nLqiJuvquRD/zwRT57VS2ffseqc0LQRIuFLPSdCb+ieuhgJx9/28qQlBkLDLq9jExMnh36AzMfs+fipfzzI0dp7hlmRQh61Q2nBqgpylzwMCyYqOYbK3N5eQHzVPfv72BNaTa1c9wIcOf6Uh46eIb9bU62LF240o1VeocncI15xKJaJMRGqxsCstKSOXzrNTxyy9v47p4t/OUVK3nHmhLKctPnPc900dJ8HvzsW3n35kq+8/hx9tzxEq39oyGWfH40tjpJTlJsCDJi+mwsK8xkU2Vu3MX+8zuIlOcueVN6KJ0qtNbsa+lnawiGYf3sqCmgsdWJ2zN3x4YO5xgNLQPcMMvaqZm4ck0pjiQV995/EuNvcRE3igpMBOpQk52ewrc+tJnvfGgzb5wZ4p3ffZb79kfflbvxtJN15TkL8jCbzvV15Rxocy0ar8dg8K+hCrSo4M1OFQv1cjvRM8LAqGde8f3Ox46aQia8vrN7jc2FB21n43yx/S5EbkYKO2oKeCzeFZW4pi8q4kpRhZN3b6nk4c9dTm1pFp+98zU+f08jw+PeqMgy6dMcaAtu6/m54B+vf/Bg/FhVHeexqMA4VYQiUsW+FjNEF4r5KT8XLy9AqfltpPjAgQ42VeayvChz9swzsGt9KU3dw2EP4BtNTnQPk5nqoDw3ffbMQtQRRTUHqgsyuOcTl/LZq2r53WvtXPdvz86rx7tQmrqHGZmYDLmiqsrPYHN1Hg/sjx9F1el0k6SgZIZNDAOdKhZCw6kB8jJS5hVv8XzkZqSwtiyHl+e48Lelb4T9ba55Dfv52bmhDCCurSp/jL9YXn4iTCGKao4kO5L4/M7V3P2JS/FOat5/+wvc9mQTk77IbeUdqoW+M3F9XTlHOgfjpjfd4RqjNCd9RicYv1PFQiNV7GsZYNs8A9FeiB01BexrGWDC6wv6HP8c43XzGPbzU5m3hA0VOXE9T3W8e0gcKRYRoqjmycXLC3joc5dzzcYy/vmRo3z4Ry9FbD+fxlYnOenJ1BTOb2jnQpwd/osTp4ozLvcFh3cW6lTRNzxOc+9IWJYv7KgpwO3xcbDdFfQ59+/vYOuyfCrzzh3qnAu71pfx6ukBeobib6+yQbeHrsFxiZq+iBBFtQByl6Tw/Zu28M/vr+Ngu4trv/ssD0dgfue1007qq+cXMX02ynOXsG1Zftx4/3W63JRfoNFeqFPFvhCun5rOxTVG+QU7T9XUPcQbZ4a4PgRrg3auL0Vr+EMc7lHlD51UK4pq0SCKaoEopfjAtmoe/OzlLCvM4C9/+Sp/+9sDeCaDH66ZCyPjXo51Dc0aDXshXF9XztGuIY53DYXtGpFAa02Hc4yKWSbMF+JU0dAyQKojiU2VoVkmEEhRVhqrSrKCnqe6f38nSsF1mxauqNaVZ1OVvyQu56nENX3xIYoqRNQUZXLvJ9/CJ96+gjtfaeWXL7WE5ToH2134dHjmp/y8c1M5SrHoraqBUQ/jXt+MHn+BLMSpouFUPxsrQ7tMIJDtNQU0nBqYdQ5Ua839Bzq4pKaQkpyFe7Ippdi5vpRnm3oZCZN3q9Y6KvugNfUMk+pIYmlB/ERgiXdEUYWQ1OQkvrx77dlYbfNZrDkbfi/D+qrwKaqSnHS2Ly/ggQMdaB05J5FQ458znL6GajrzdapweyY51D7ItvNs8R4KdtQUMDzu5UjH4AXzGQeYkVk3SJwLu9aXMeH18cyxnpCVGch3Hj/OJf/0h4gvoj/RPczyooyYiTIjzI68qRCjlOKWq1fTPTTOL8OwQV/jaSdLCzIoDEGongtxfX0FJ3pGeOPM4h3+67TxHmezqGB+ThUHbSDaUC70nc6OmkKAWYf/HjjQiSNJce3G0Cmqi5fnk5eREpbhv2eO9fBvTxzHp2HvqYVvaTIXmrqHZdhvkSGKKgxcurKQS1cUcvtTJxibCK1V1djqDFl8vwtx7cYyktTi9v7rDNgwcTZKstO5et3cnCoa7C68oQydNJ2y3HSWFWZcMO6f1pr793dw2aqikG5ZkexI4sq1Jfzhje6Qzrmecbm5+e5GakuyyEx1sD+CaxHdnklO94+Ka/oiQxRVmLhl52p6h8f5rxDOVZ1xuTkz6A75Qt+ZKMpK49KVhYs6SkWH002KQ1GUGZz1+eEdxqni0SCdKva19LOiKDPs1u2OmgL2nurHd555qv1tLtoGxrghDJHAd60vwzXmCZnV45n08Zk7X8XtmeQHf7SVTVW5EV00f6pvBJ9GXNMXGaKowsT2mgIury3ih0+fCNlk9NmFvhFQVADvWFPCyd4RuociP+EdCjpdY5Tlpgftxu93qvhVEEO2Pp+moWUgrNaUn+01hThHPRzrnnkY9v79HaQ6kthlI0qEkretLiItOSlo5T0b//LIUfaeGuCf3ruJVSVZ1FfncaRzMGK7Ch/vEo+/xYgoqjBy89Wr6RuZ4Bcvhsaqeu20k1RHEuuD3LF1odRbhXigNfgFp7FEp9NNeU7wC1/n4lTR3DuMc9QTlvVT09lxgfVUPp/mwQOdvG11MblLQr/BZ0ZqMpfXFvHYka4FO9Y8dqSLf3+mmT/asZQbN1cCsKU6D8+kntVZJFQ0dQ+jlNksVFg8BKWolFK7lVJHlVJNSqkvz3D820qpRvtzTCnlDDg2GXDsvlAKH+tsXZbP21cX8+/PnAhJANvXWp2sq8gJ2fbps7GhIockBQfmEBkhluhwjQU1PxVIsE4V/vmpcHr8+anKX0JFbjovN5+rqBpaBjgz6F5QbL/Z2Lm+lHbnGEc6569MWvtH+cI9jWyszOH/XL/+bLq/MxSpeaqmnmGq8zPCtpxACA+zKiqllAO4DbgWWA/cpJRaH5hHa32L1nqz1noz8D3gtwGHx/zHtNbvCqHsi4Jbdq7GOerh5y+cWlA53kkfB9tcYV3oO52M1GRqS7I50Bb5wLsLxefTdA26g/L4CyRYp4qGlgEKMlNZMc8I5XNBKcWOFYW8fLLvHKvm/v0dpKckcfW60rBd/6p1pSg1/yC1495JPv2rV9HADz689U1Kojx3CaU5aRGbpzohHn+LkmAsqu1Ak9a6WWs9AdwF3HiB/DcBd4ZCuHhgc3UeV60t4Y5nmhl0e+ZdzrGuYcY8oY+YPht1VbkcaHMtuvVUvcPjeCb1rGuoZiIYp4p9LQNctDQ/YtG3t9cU0Ds8QXPv1F5h3kkfDx/q5Kq1pWSmhW+z7qKsNLYuzZ/3PNU/PfQG+9tc/PP761laeO4i2/qqPPa3hd9qn/RpmntHRFEtQoJRVJVA4DhIm007B6XUMqAGeCIgOV0p1aCUekkp9e7znPdxm6ehpyc8iwujyc1Xr8Y15uGnz52adxn+HmfEFVV1Hv0jE7QNRCbgbqjomMMaqum8dVURVfnnd6roGRrnZO9IROan/PjnqQKH/15q7qd3eCKsw35+dm0o5Ujn4JwX5z54oJOfvXCKj761ht0bZ3b22Lw0j5O9IzhHJ0Ih6nlp7R9lwusT1/RFSKidKfYA92qtA8dMlmmttwEfBr6jlFo5/SSt9R1a621a623FxcUhFin6bKrKZef6Un78XDOusflZVY2tA+RnpLBshh5pOKmzMezmEsE7Fuh0+jdMnLtFlZSkuGn7+Z0qzgaijYDHn5+aokyKstJ4JWDh7wMHOshMdXDFmpKwX3/neqNkHp9DkNqTvSP8zW8OsGVpHn+ze+158222UVbCbVX5Y/yJa/riIxhF1Q5UB/xfZdNmYg/Thv201u32dzPwFLBlzlLGATdfXcuQ28t/PHdyXuc3tpqI6ZHe6G1teTYpDsX+RTZP5beoKua53YXfqeLuGZwq9rX0k+pIYmMYAtGeDzNPVcDLJ/vRWjPh9fHwoTPs2lAWEceAmqJMakuygh7+c3sm+dQvXyXZofj+hy8iNfn8Tc2mqlyUMlFXwolsP794CUZR7QVqlVI1SqlUjDI6x3tPKbUWyAdeDEjLV0ql2b+LgMuAI6EQfLGxoSKXazeW8ZPnTs55iGPI7eF493DEh/0A0pIdrCvPWXQu6p3OMdKSk8jPmJ/Ltt+p4tczOFU0tAxQV5Ubcc+xS2oK6HS5aRsY47mmHlxjnpBs6REsO9eX8sqp/qDq79fuO8zrnYN8+4ObZ90bKzs9hVXFWWHvDB3vGqY4Oy0sbvxCeJlVUWmtvcCngUeA14F7tNaHlVK3KqUCvfj2AHfpN8+6rwMalFL7gSeBb2qtE1JRAXzu6lqGx7386NnmOZ13sM2F1pGfn/JTV5XLoXbXeSMjxCKdLjcVeUsWZIHeNINThQlE62JrBOen/Gy3cf9eau7jgf2d5KQnc3lt5IbKd20oY9KneeKN7gvm+82+Nu7a28qnrljJO9YGNyy5uTqPxlZnWJ12mnqGZQ+qRUpQc1Ra64e01qu11iu11v9o076itb4vIM/XtNZfnnbeC1rrTVrrevv7P0Ir/uJibVkO19WV87PnT9E/ErxV9VqUHCn81FXmMTTu5WTfyOyZY3HgINwAACAASURBVIQO19i85qcCudw6Vdz5ypRTxYE2F55JzbYw7Og7G7UlWeRnpPDs8V4ePdLF7o1lFxxSCzV1lbmU5qRd0E39WNcQf/+7Q2yvKeDzO1cHXXa9ddpp7Q+P047WWlzTFzESmSLC3HxVLaOeSe54JnirqrHVSU1RJnkZoQs4Ohfqqs1czGJaT9XpnPsaqun4nSpeONHHSesW7o95F4nQSTPJc/HyAu4/0MHwuJcb6isifv2r15Xy9LGeGbewGRn38qlfvkpmmoPv3bRlTtto+DthjWGqY12D4wyPe0VRLVJEUUWY2tJs3lVfwc9fOEXv8Pis+bXWNLY6o2ZNAawqzmJJioP9i2Seyjvpo3vIPa81VNM5G6nCWlX7WgZYUZwZ0ijlc2HHikK0hsLMVC5dURjx6+/aUMboxCQvnOh9U7rWmv/93wc50TPMd/dsoXSOmzeuKcsmPSUpbA4VZ3f1Fdf0RYkoqijw2atqGfcGZ1V1uNz0DI1HVVElO5LYWJmzaCyq7qFxfHp+a6imE+hU4fZMsq9lIKJu6dPxr6e6dlNZVDb+u2RFAVlpyed4/921t5XfNXZw81WruWxV0ZzLTXEksbEiN2wOFU02oK9YVIsTUVRRYGVxFu/eXMkvXjw1a2Ryfw8zmooKYFNlHoc7BvGGcF+icDGXfaiCwe9U8YOnTuAa80Qkvt/5WF+ew5euWcMn337OcsSIkJbs4Io1xTz+eheT1rnmcIeLr953mMtri/j0lavmXfbm6jwOtbtCuveVn6aeYbLTkynODu+WLEJ4EEUVJT5zVS2eSc0Pn7qwVdXYOkBqchLryiMTMf181FfnMu71cawr+K3ao0WH066hCoFFBVNOFbc/1QREdqHvdJKSFH/1jlVU5Ud24XcgO9eX0js8QWPrAINuD3/1y1cpyEjlOx/ajCPILVVmor46j3Gvj6Nh2FXav6tvpNchCqFBFFWUqCnK5L1bKvmvl1voGjy/VdXY6mRDRU5Evbtmos5GD1gMw3+htqj8ThWeSU1hZio1EQhEG8u8Y20JKQ7Fo4e7+PJvDtA6MMb3PrxlwRtI+kcNXgtDgNqm7hGZn1rEiKKKIp+5shafT3P7UydmPO6Z9HGw3RX1YT+A5YUZZKcnRyR46ELpcLrJSksmJz10Czs/sNU4VVy0LHKBaGOVnPQULllRyE9fOMVDB8/w19es4eIQDIdW5S+hMDM15Ft+OEcn6B0ep7ZUFNViRRRVFFlamMH7t1bxq5dPn7UCAjl6Zgi3xxcTikopRV1VLgfbF4dFtdA1VNMpyUnn+x/ewhd3rQlpuYuVXetLmfD6uHpdCR+7fEVIylRKnV34G0rOevyJI8WiRRRVlPmrd6xCo7ntyaZzjvk/2C3V0ZsTCaSuKo83OodmXEMTS3S63JTPM8bfhdi9sZw1ZdkhL3cx8u4tlXzmylX86wc2k7SAeanp1FfncaJneEFb4kxnyjVd3t1iRRRVlKkuyOCD26q5e28r7c43W1WNrU4KMlOpLgh9ozsf6qty8fo0ry9gp9dI0OF0UxFii0p4M9npKXxh1xpy5xlL8Xxsrs5DaxM2LFQ0dQ+TlpxEZX5sfEfC3BFFFQP81TtWoVB8/4k3W1X+hb6xMiey6axDRezOU417J+kdHg/JGioh8tTbOhbK4b+mnmFWFGctyCNRiC6iqGKAirwl7Nleza8bWs9uTDfo9nCiJzoR089HRW46RVmpMa2oulwm2keoPP6EyJKbkcKKoszQKiqJ8bfoEUUVI3zqilUkJSm+98RxAA60Rjdi+kwYh4q8mHZR73DNf8NEITaoD2Ek9bGJSdqdY+KavsgRRRUjlOWm80c7lvKbV9tp6RuhsdXsIlsfQ4oKzJYfTT3DDI97oy3KjJxdQyVDf4uWzdV59AyN0+m6cNSWYDjRM4zW4vG32BFFFUP85RUrSXEo/u0PTTS2OllRnBlzm7zVVeWiNRyO0a3pz0alkKG/RYu/cxaK4T+/x5+soVrciKKKIUqy0/njHcv479faeKm5P6aG/fzUxbhDRadrjNwlKWSkJkdbFGGerCvPJtWRFJKFv03dwziSFMsLEzuayGJHFFWM8Ym3ryQt2cHwuJctMaioirLSqMxbEvZtw+eL2YdKrKnFTFqyg3UVOSEJpdTUPcyygoyohyATFoa8vRijODuNP33LMgC2LI2Nhb7TqavKjVmLqsNuQS8sbrZU53GwzbXgaP1NPcOslPmpRY8oqhjklqtX86M/3caGiuhGTD8fm6pyOd0/inN0ItqinEM4wicJkae+OpcxzyTHu+cfrd8z6eNU74g4UsQBoqhikPQUBzvXl8bMQt/p1MfoPNXYxCTOUY9YVHHAZhs2bCHzVC19o3h9WlzT4wBRVMKc2ViZC8Telh+yhip+WF6YQe6SlAV5/kkw2vhBFJUwZ3KXmOgBsbblR6d1TZc1VIsfpdTZhb/z5USPUVQyR7X4EUUlzItNVbkhDRwaCvwWlayhig82V+VyrGuIkXkuLj/eNURFbjpZabJUYbEjikqYF3VVeZwZdNN9gd2JI43foiqTob+4YPPSPHwaDs1zcbl4/MUPoqiEeVFfZeapYmn478zgGEVZqaQlO6ItihACFhJJ3efTnOgWj794QRSVMC82VOSSpGLLoaLD6Zb5qTiiMCuN6oL5LS7vcI0x5pkURRUnBKWolFK7lVJHlVJNSqkvz3D820qpRvtzTCnlDDj2EaXUcfvzkVAKL0SPJakOVpdmx5SLuqyhij/qq/JoPD13RTW1q68oqnhgVkWllHIAtwHXAuuBm5RS6wPzaK1v0Vpv1lpvBr4H/NaeWwB8FdgBbAe+qpSKzXALwpwxESpCsx1DKOh0SlSKeGNzdR4drrnPhYprenwRjEW1HWjSWjdrrSeAu4AbL5D/JuBO+/c1wGNa636t9QDwGLB7IQILsUNdVR4Dox7aBsaiLQpDbg9D416xqOKMLUvnN091omeY/IwUCrPSwiGWEGGCUVSVQGvA/2027RyUUsuAGuCJuZyrlPq4UqpBKdXQ09MTjNxCDOCf7I6FALX+vYvKxaKKKzZU5JKcpOZcx2RX3/gi1M4Ue4B7tdaTczlJa32H1nqb1npbcXFxiEUSwsWaMrMdQyysp+pw2jVUYlHFFekpDtaWZ8/JotJac7x7mFUl2WGUTIgkwSiqdqA64P8qmzYTe5ga9pvrucIiIzU5iXXl2WJRCWGlviqPA60ufL7g5kL7RiZwjnrEooojglFUe4FapVSNUioVo4zum55JKbUWyAdeDEh+BNillMq3ThS7bJoQJ9RV5XGofTDoRiRcdDrHSFJQmi1zEvHG5uo8hsa9NPcGF0ldHCnij1kVldbaC3wao2BeB+7RWh9WSt2qlHpXQNY9wF06wAVMa90PfB2j7PYCt9o0IU6oq8pleA6NSLjocLkpyU4n2SFLA+MN/07XrwXppi6KKv4IKgiW1voh4KFpaV+Z9v/XznPuT4CfzFM+IcYJ3Jo+mnMCna4xCZ0Up6wsziIrLZn9bU4+sK161vxN3cNkpDpkvjKOkO6nsCBWlWSRkeqI+sJfs4ZKGqZ4JClJUVeVG7RDxYmeYVYWZ8Xsfm7C3BFFJSwIR5JiY0VuVB0qtNZ0uMYkfFIcs7k6jzc6h3B7ZncoFtf0+EMUlbBg6qpyOdIxiGfSF5XrO0c9uD0+Wewbx9RX5+H1aQ53XNhyHx730ulyi6KKM0RRCQtmU1Uu414fx7qGonL9qX2oxKKKV7ZU+yNUXFhRnRBHirhEFJWwYOoDHCqiwdTOvmJRxSslOemU56bPOk91XBRVXCKKSlgwywozyF2SErUtPzrFokoINlfnsX8WRdXUPUyKQ7GsICNCUgmRQBSVsGCUMl5Z+2cZlgkXHS43yUmKIglAGtfUV+dxun+UvuHx8+Zp6h5meWGmrKeLM+RtCiFhU2Uux7qC88oKNZ3OMUpz0nEkiTtyPONf+HuhIeYTPeLxF4+IohJCQl2V8co60jkY8Wt3uGQNVSKwqdLsKv3aeYb/xr2TtPTJ9vPxiCgqISTUV+cCcGCO+waFgk5ZQ5UQZKYls7o0+7zzVKd6R/FpcaSIR0RRCSGhLCed4uw0DrRHdp7K59OccbkpF4sqIaivymP/eXaV9sf4Wynbz8cdoqiEkKCUoq4yN+Iu6n0jE3gmNRViUSUEm5fm4Rz1cKpv9JxjTd3DKCWKKh4RRSWEjLqqPE70DDM87o3YNf2u6bKGKjE4u6v0DMN/TT3DVOUvYUmqI9JiCWFGFJUQMuqqc9GaiO7422EX+8oaqsRgdWkWS1IcMy78Pd41xCqxpuISUVRCyKirNA4VB9sj51AhFlVikexIYlPluZHUJ32a5l7x+ItXRFEJIaMwK43KvCXsj6BF1elyk5acREFmasSuKUSXzUvzONIxyLh3as1e28AoE16fKKo4RRSVEFLqq3MjGkqpwzlGeW667D2UQNRX5TEx6eONzqkgyLKrb3wjikoIKXVVebT2j9E/MhGR63W63LKGKsHYvNQfSX2qQ3RWURVHb5dpIXyIohJCytQ8VWSG/zqdY7KGKsGoyDVr9vZPU1RFWWnkZqREUTIhXIiiEkLKxqrIRaiY9Gm6hsZlDVWCoZSivirvzRZVzzC1MuwXt4iiEkJKTnoKK4ozI+JQ0T3kZtKnxaJKQLYszaO5dwTXqAettWw/H+eIohJCTn1VXkQcKjpkw8SE5ezC3zYn3UPjDLm9oqjiGFFUQsjZVJlL99A4XYPusF5nag2VDP0lGnU2CPL+Vqd4/CUAoqiEkFMf0IiEE/8W9DJHlXjkpKewsjiTRlFUCYEoKiHkrC/PxZGkwh6gtsM1Rkaqg5wlyWG9jhCbbK7OZ3+bUVTZacmUZMsOz/GKKCoh5CxJdZh9g8I8T9XpdMti3wRmc3UuvcMTPH2sh5UlWVIP4pigFJVSardS6qhSqkkp9eXz5PmgUuqIUuqwUupXAemTSqlG+3NfqAQXYpu6ylwOtrtm3DcoVHS6xiQYbQKzuTofgNP9ozLsF+fMqqiUUg7gNuBaYD1wk1Jq/bQ8tcDfApdprTcANwccHtNab7Y/7wqd6EIsU1edi3PUQ2v/WNiu0eFyi8dfArOmLJvUZNOEyRqq+CYYi2o70KS1btZaTwB3ATdOy/Mx4Dat9QCA1ro7tGIKi41A9+FwMOH10Ts8Lh5/CUxqchIbK3IAcaSId4JRVJVAa8D/bTYtkNXAaqXU80qpl5RSuwOOpSulGmz6u2e6gFLq4zZPQ09Pz5xuQIhNVpea3m641lN1DbrRGipksW9CU19tOkSiqOKbULlLJQO1wBVAFfCMUmqT1toJLNNatyulVgBPKKUOaq1PBJ6stb4DuANg27Zt4ZvUECJGanIS68pzwub51+GUNVQCfHj7UlKTk6jOz4i2KEIYCcaiageqA/6vsmmBtAH3aa09WuuTwDGM4kJr3W5/NwNPAVsWKLOwSKivyuVQu4tJX+j7Hp0u/86+YlElMrWl2fzttetIShKPv3gmGEW1F6hVStUopVKBPcB0773fYawplFJFmKHAZqVUvlIqLSD9MuBIiGQXYpy6qjxGJiZp7hkOedkdEpVCEBKGWRWV1toLfBp4BHgduEdrfVgpdatSyu/F9wjQp5Q6AjwJfElr3QesAxqUUvtt+je11qKoEoR6G0k9HAFqz7jc5KQnk5kmi30FId4J6ivXWj8EPDQt7SsBf2vg8/YnMM8LwKaFiyksRlYUZ5GR6uBgm5P3b60KadkdTresoRKEBEEiUwhhw5Gk2FiZS2MYLKpO15isoRKEBEEUlRBW3rqqiP2tTlr7R0NabqfLTblYVIKQEIiiEsLK+7dWkaTgnobW2TMHidszSf/IBBViUQlCQiCKSggrFXlLePvqYu5paMU76QtJmX7XdPH4E4TEQBSVEHY+dPFSugbHefpYaKKOdPoX+8oaKkFICERRCWHnqnUlFGWlcecroRn+63DJhomCkEiIohLCToojiQ9sq+LJo90h2Z7eb1GVyRyVICQEoqiEiPChbdVM+jT37mtbcFkdLjcFmamkpzhCIJkgCLGOKCohIiwvyuTSFYXctfc0vgXG/pM1VIKQWIiiEiLGnu3VtPaP8cKJvgWVY7agl/kpQUgURFEJEeOaDWXkZaRw197TCyqnwzUmUdMFIYEQRSVEjPQUB+/ZUsmjh7voH5mYVxnD416G3F6xqAQhgRBFJUSUPRcvZWLSx29fnZ9Thd/jTywqQUgcRFEJEWVNWTZbluZx195WTND9udEhUSkEIeEQRSVEnJsuXkpT9zD7WgbmfO7ZqBTi9ScICYMoKiHiXFdXTlZa8rwiVXS43Cgli30FIZEQRSVEnMy0ZG6or+DBgx0Muj1zOrfTOUZxVhopDqm6gpAoyNcuRIWbtlfj9vj4n8aOOZ0n+1AJQuIhikqICpsqc1lfnsNdr8xtTVWHa0z2oRKEBEMUlRAVlFLs2V7N4Y5BDrUHt1W91pozLolKIQiJhigqIWrcuLmS9JQk7gzSqhoc8zI6MSlrqAQhwRBFJUSN3CUpvHNTOf/T2MHohHfW/B0uv2u6WFSCkEiIohKiyp6LlzI87uXBA52z5u10yc6+gpCIiKISosrFy/NZWZzJXXtnX1PV4ZSdfQUhERFFJUQVpRR7Ll7KvpYBjnUNXTBvp2uM5CRFcXZahKQTBCEWEEUlRJ33XlRJikNx9yxWVafTTWlOOo4kFSHJBEGIBYJSVEqp3Uqpo0qpJqXUl8+T54NKqSNKqcNKqV8FpH9EKXXc/nwkVIIL8UNhVhq71pfx21fbGPdOnjdfh+zsKwgJyayKSinlAG4DrgXWAzcppdZPy1ML/C1wmdZ6A3CzTS8AvgrsALYDX1VK5Yf0DoS4YM/2agZGPTxyuOu8eSQqhSAkJsFYVNuBJq11s9Z6ArgLuHFano8Bt2mtBwC01t02/RrgMa11vz32GLA7NKIL8cRlK4uoyl/C3efZ/VdrTafLLVEpBCEBCUZRVQKBkwdtNi2Q1cBqpdTzSqmXlFK753AuSqmPK6UalFINPT09wUsvxA1JSYoPbavm+aY+WvpGzjneNzLBhNcnUdMFIQEJlTNFMlALXAHcBPxIKZUX7Mla6zu01tu01tuKi4tDJJKw2PjAtmqSFDM6VXQ6ZcNEQUhUglFU7UB1wP9VNi2QNuA+rbVHa30SOIZRXMGcKwiA2WPqHWtK+PW+NryTvjcd80elkPBJgpB4BKOo9gK1SqkapVQqsAe4b1qe32GsKZRSRZihwGbgEWCXUirfOlHssmmCMCN7ti+lZ2icJ97oflP61M6+YlEJQqIxq6LSWnuBT2MUzOvAPVrrw0qpW5VS77LZHgH6lFJHgCeBL2mt+7TW/cDXMcpuL3CrTROEGXnHmmJKstPOiVTR6XKT6kiiMDM1SpIJghAtkoPJpLV+CHhoWtpXAv7WwOftz/RzfwL8ZGFiColCsiOJD2yr4vanTtDpGjtrQXW43JTlppMki30FIeGQyBRCzPGhbUvxafh1Q9vZtE6nLPYVhERFFJUQcywtzOCtq4q4e28rPp8GzNBfhSz2FYSERBSVEJN86OJq2p1jPNvUy6RPc2bQLRaVICQooqiEmGTXhlLyM1K4e+9peobGmfRpCZ8kCAmKKCohJklLdvDei6p47EgXB9tdABI+SRASFFFUQsxy0/ZqPJOa7z/ZBMgaKkFIVERRCTHLqpJsti3LZ3+rE5CoFIKQqIiiEmKaD11sInAtSXGQuyQlytIIghANRFEJMc11deVkpyVTnpeOUrLYVxASkaAiUwhCtMhITebvrluHZ1qQWkEQEgdRVELMc9P2pdEWQRCEKCJDf4IgCEJMI4pKEARBiGlEUQmCIAgxjSgqQRAEIaYRRSUIgiDENKKoBEEQhJhGFJUgCIIQ04iiEgRBEGIapbWOtgxvQinVA7QsoIgioHeBYiy0jFiQQcqQMsJdRizIIGVMsUxrXbzA68ckMaeoFopSqkFrvS2aZcSCDFKGlBHuMmJBBikjMZChP0EQBCGmEUUlCIIgxDTxqKjuiIEyYkEGKUPKCHcZsSCDlJEAxN0clSAIghBfxKNFJQiCIMQRoqgEQRCEmEY2ThSEOEQpNQkctP/WA68DS4Aq4AiQCrQD5YAPqAT6ATegAK89t9z+3QuUAKVALfBjYAXwLeDbwMXA3wPvAg4Dk4AD2A9ssf9vAN4CvAp8HXgfMGKv7QHGgDNAns2fBNwG3AC81crQAHwGWAc8rrVOVkptBh4AcoFTwDe01ncv7AkKMYXWel4/wLsBDaydlr7Zpu+elj4JNGIq8X7gC0BSwLFJTEV1A78POHYF4LLnaqAvIG8fpmIeBZoC0scAJ5AFfM2edwbzwfnP08A+oA142KZN2PRJ4BLg3+z//vQm4BDmw+6z8t1hy/UF/HTa+xi1573fXmfQ5tXAMHAp8JcB5Wt7/kHMR+mXxWf/brW/v2h/n8J8uMcD8ozbZ/WnVr7fAS/Z59Bujx0CPmfz/wXwlH1ePnvdQ1bmyQCZ/PKN2d+ngV8GPEv/j/9exoF7AtK9Ae/xE9PO8f8M2Tx62nV99h27gB4rw6h9H//bpgc+w0n7fH3TyvfZd/Af9u8xTAM5YZ+lP/+YPd/Jm+vEuD32E0wj+jN73F/WiM33xYC668TU9dMBz9MvixtTxx6wcviv47HX6rV52gLOGbK/R+x71cDH7HNxY+qCBiatDMMBz3/YljvAVJ09BnQAdwLbA55JE0ahNQEbbVkP2fM67fUnAvL32DT//TXae9ZAiT1/BHgD+CamDficPW8AaAb+YN/lf2Pqa6eV9zTwNKZOXgFsxChFDazFfBcHgTVM1aM8e80iK98h4IS913F73432Gq8DB+z/OwLarDGm6uzrwElMPeyy7/WoLdffpu0Huu01DmDanG57/rB9XnkB5f/Ovu9t9r408BcztKX++vQzK0OjfY5fDcj7lH1Oalr5wwH/12Lq2glM2/ck8LZp7fTvgJdmaO+/aK/ZCOzFti+R+lnI0N9NwHP2dzDpY1rrzVrrDcBO4Frgq/bYBPCw1noJpuK9Dbg94NxntdabMRV9DHge83IzgXx7rScwH/ZyW84OTAWtwjRqLwI/BKqZajQcmF7mCozCKWWqAXkPUMFU49MK/AbTsCggWSn1J8Au4D5MxWyy9zICFGA+wlbgT4A0zMfWhPnYJ4D/Av4F0+g9AGQDH7cyDmA+qDsxjU+blW/UPhMNLAU+ap/ngL3fDvucf6GUygO2Ynqa+cC37XP8APBP9j39A6ZHfLt9ttfa4/9p5Wq372kc+Ip9xiMYa7wP8wHvs2n+BnYEE13kEqYUQW/Ae9xo800Ch7XWCnjc5jtu0w/aazwNXG/L6sV0PsqAv7Lv8QTwLKbh8Hd4DmGUib/T0m2f8yqMknqflfu79p2u1lovt9efxDSIp+09DNvnvQV4L6Ynv5qpuvsCcMbWubfZ5/UX9lg6po5+B/h3TAOqbRl9GAWzDHjM/v839jrfts9e2+NpmHrZg6lro/Z+f23v9YtACqZu/dbmVUqpJVYOjWlUD9p7SrbPpRPT4N+L6fB0YxT2ALAJ+B5QjLGWsM/nVUxdbGTK0vJ3gG611xqx7/n79ryPKaV22+exHKO432uvnWtlclk5HJgOXD7wDOb7+X82zaG1fkprfQi40pb9b0AO8ClMnTpp788foeHPrUwrMN/1hL1WFVBor+/G1KsVwBal1G6l1FMYq/NZ4Gb7XErtPX4H01gfte+rCNNefBKjcHdpreuAXwA/tM+iAdPQb8S8nDyMtRrIIeCDAf/fhFF+gXzJlrcZ+IhSqibgmBO4bKbylVLpwIPAHVrrlVrrrRjLdEVAnrPthVIqMP2TmDZmu732VZg2MHLM05rKwlTO1cDRgHSFeVErMb2K9IBjw9PKWIH5OBXmo3kg4Nj9mI9aYXoaDwT0Dp/ANIy3YirpOObl/gY4MoOsd2N6T82YD2clpmc4iGmsmjAfvgNTqcftdT6P+VD9vdD/xnw0fgti1Jb5K0zD3IGp8H6L7TqMInjcpnvtPfXZ/+9nqpfsA+7C9JDvw1gcblvucUyP7WamevR+i6od+GvMx+/FNDATwCsYpff3mN5fp03vwTRG99j8P7fl9GAa3MP27yR7fX9PvN2Wuc0++1HMh/pze82D9hpj9nojwD/bYz5M4++1z/ybNv0pW74b08i127x9Nu8JppTeI1amCZvmwHRoxjENxIuYYauj9ho9mAb7pP2/C/hrWx8+Y99pM0aJHgx4XuP22v322BuYhlkDRfb8rwH/18r5GKZx8PfiT2EaNg9TFocX0wnpteX5MJ2PPoyivA+jOM8EyPgx+8xcmGG71+x5z9tn1YepK7fbsvvtPRzCNGx+K/AkU1bcIFOdiX1MWWYTmDoxypT1HmjJeqf9PYmpu/6hOn8dGbfyBVreYwHn+tM7MIqu297H00wN6b1mz/Ha93PYlrvXluG3Tg5Ok7EBUzc/z1QH6CHMd+GxeVrts3qcN1uL/hGcn9q8d2MU3ZB9Ns32+fq/jS/bc39nf5+2z/U1jMJ90r7DTJt22v4+CPydfWd32edwiDdbVA9glHMpsNu+Ex/mezlsn1MLU9+LX+k+jfme7rD3c9Lm+z/2eT5tZRjCfH9/hKkvB4GVAW3lnwM/wNTxZ618B+z9r7DnHrFp/8JUJ8M/+lVjZfZbl2+xz+FB+/8h4EP23n4dcN0rCGj/Q2lR3Qj8Xmt9DOhTSm216W8BTmqtT9gHd935CtBaN2ManJLAdKVUIaY3p6cfs6zHPPCNmIedgvnIHwbWKqVGlFJnlFLfsvlPYB5WBcb6+TJG2aVjKvUTGKvqceBvMRUHTGN+A5CBadjqrDxuTOV5FWP5bMT0eF2YCu4fXroT0+tJwfTMG697aQAADUVJREFUJu3f7RgFvB3zYQzYe/2Qvbcr7fn+D32Flf+PmBq39/OfGItqpX2W/sYgHdMz+jimJ/9DK9e3gWuYmjO4xF4jE/Nx+K3HTzJlSTjssXWYj7/Clt8B7LHnLsM0uOn2XpOZahTdVma/7B+wstTZtEH7HvZbWYZsvhW2rCWYoSf/8NoE5kO8F6MkBjBKRmE+yHRMDxtMrzwb0+N9v1Jqiz3mw3xUyub3Py+Hve9hTMOWjrEiAQ4ppX6K+Zhvt/f4FkynDft/Jea9uoDPYjoxJ+17ysBY2QpjsRXYd3EQY+XlA1cqpSow9f8Upr48iJnbmcTM69Rh5nBGgHfYa49jOo219h4UUwpp3ObJsveTjOlpZ2G+m9P2OsmYRlnZsv+MqQ4Z9p79isE/BJ2O6aCM2neVHZDn7fZZYK9x0B7LxbyzfEwd2mTfyWta6y0YqxL7DtbYsj+BaaS9GIthP1MdmwlMfV6BGUrEltEM/MjeTyOms7oT06mptGXn2OPXYEZgXsFYj/U2PQXzLocxyizflttkzymxZRy1ZfYB25RSxzAKZ9C+j2TMO3w/pu0cY8oSnt4G3wv8L0wn8EErx+N2JCoFU5fBvMPv2PfUbtPW2+tttDL+yqbX23v7KmZ0Z7XWejtmnvEzAde+CdNuaUw924yZG0yyz+E9wAZrLX5Da+0fFn27Pf+XwH6tdT1wEUa57saM8tRrrTfa5/g4sEMplWnP+xBGeZ+feVpUDwA77d+fBf7F/v194GP273cB957PorJpTkwj6B8Lfg3zcX0y4NgVAccmMZO3Lnvcbw358z2MGVL4gT2+DtM7+BKmB+SfT2jGVJR9mF7YKcykbZc9PmzlS7PXPGxfngdT+fowvXy/9TJmr3OCqTF8jy13wub3DyP5e+BOzIfai2mATjLVE/ZiGgt/z3XI3qfH/vgtqq02/Wl7zjcxHQXsM+mxsh+01+vCVCwPpuE5atMbMIrG3wM+g7FW/Y1Sj033f6Q+TOXttvflHzLTtlz/fMgwU5bhq/b5fN/+7bdUAnvrJ22ZE5he3HGm5iSbrKyjmA/TY5/dz6zc/vf6DKZ+nMQ0nN1MdS4mMVbun2Aa8E57r39mn1ng/NoA8IJN18AtGAvI/66HrRwnrCxlmDr6q4B37h8iS2fKGtFWvjFM4/lFjNLy35vfOum3+dqZmrdrsvc8gWnQJjC9298CL2Pqpn9e0GPfq9+ieNFer91e042xCD+Gqfu32/fss+/od/be/M/kCftM/daZfz7t/9lzPPZ+/RbZSabqTY+V02/t9Nn7/x3mG/DP/53ANFheTN0PtMSGbDnr7Dvz17Ov2/Pvte/6NEZp7sfUu1FMXfuBLe/rGAvt48AfBzy339p7GGXKotC2DCfmG3Jjvpl++2w/Zs91Ydq7b9v/fx9wXwOYOuDGKKpm4B8xw+BwrkVVZq91FNOx9jFlaR+0z+mzmHreZ8tqxbQBD9jn+nPgZT01z/YYpt38nD3vMswI0UmMEgHTXpzCKMbfYL69jRhFPIBRtvsxQ+rvBVLteR/GDG9iZXvntDZ+tS33/wMuD0i/A9PRTbbvLDukFpVSqgDT6/+xUuoURgl8UCnlwAxhfMWmfw/YrZTKPk85KzAvqdsmPau13mLHTh+d6Rjmod+HqUTfw/TwxwLyTWqtf6u1/hRm/uedNl3bvG6MYvGb0WA+jlT70L6BqRgOeywT0yBXYj6KQEsBzIv2W3bpGAvrDKbBuhPTOAxiPvZS+/df2LKexAzn5WPmW17C9ND911/ClFLwy+EIkA1MT+kN4HKmvLT8fNDeVy6m95iLaaS22uewB/NROGw5dZihAhdGQV9qy1ln5Riz//uHBN9u85VglNp9mHf2bpsnw8qdZv+ux1hj78NYgGfHwDHv78OYj9Pfy9KYBtU/H/N7poa9Ntv01zHzQv5o+1mYIcEcwK219it4F+ZdPIh5N91W1lRM/X2fPd8/D/RbjNWyL6D+pmLe/ffts/M3yNhrfACj+D5qZX/d3u9qzHvtt2WDGW34G8zHmqW19nvbfc3e50uY99mH6fGm2/NKmOpsfdLe9zqmhq3SML1iv/V6H6bOakx9q2Gq9z2GsbargY9g6ojfGeJKW+7nmVLwNRjFD+bbGbTH/ArFXz+w+b9knwmYb6HKPkMwPe9JTJ3wOzkdsPd+iZVjVYCcX7f381lMvSnG9MIdGIvCh7FU2oBBrfUEphO6BNMxWc2UlXkpxjIZtrLfDaC1fi/wr/ZZ72Jqfs2FUWo32vP/yD7Xb2qtf4R5r7/GWLO/xCiTyzB14VHsnDHmnZ6yz//TmA7FOWitz9hnU45xLgnkKKYOLcGMYryI+fazMZ2dZMw7fT9Qq5Raa88bx7R5F9lnNa61fg+mY5tm83wQ0xadxFhBpcBNWutB+6yWYizkezFzxr+3592Haef9139y2v0cs9c9CHxDKeUfobjLXvNKoMF+q+dlPkN/7wf+U2u9TGu9XGtdbW/ufwMHtNbVNn0ZRjO/Z3oBSqlizHDU97VVr8Ecm8admB7Nf9t8G4FKpVSpUioVYwa3YCZMizAf+IsYSypwG5Fym/4a5qEnWTk+i2l0vJie9DHMR+MfKknBjDl77P3/ENPYFGI+5LsxDWo2pvFtx/RSsuw1xjAf0UlMo5hp8/uH3DyYBvH/YnpKzzM1jJOPaVD+DtOL88v9dit7NqbB+nNMQ/RZTK9oDWYi9DCm0vdiPsLf2OeQzZS1tNH+/VbMO0/HfOyF9pncYZ/JU5iPZxNTnp1pNs9pTG/PP8bun6NYy5utrSLMhwFGiSRjGpz/wfRAMzENmr+n/C37zjZhGpJsW95vMZX/EFCllHovU0NhpRgF5p+LScYori8CZ5RSyUwN93zG3lM9Rglgy/0IpmdfiGkQCuy782Aa9X2YBvS0fZ6jmAa9DvNhF9qyNmAatwygRimVYdPTMEr8GSurG9Pb/gf7PH+FacAdmMY3DdM4d1k5z9hnrOzvn1jZlH1uHRiljy3j85h3m8ZUxyMJ0wgux1ghaZi6WmWfmdfKl4qpP59gagiuLaDsf8GMOsD/397ZhGhZRXH8dy0akCCwiEiQQRw0MqIv2kkQZIK0atPCoEUUJNIi6GuhCG1qJaXkSoPIRaEIEkigSIlmBOJUahRlpLnIj8F3Rmdi5rT4n8O9887UO2MFL3b+m/fhee7Hufeee+655/6f5xXRYcSvFyCdG/A67vey7vW+u8vHYLmX+RkykLegObYJ7ZCOoHFc43IVFAJcVko5T2XrhQMX589DaBH+wJ+/DAyUUo4DzyI9egAtYiC92YccqWjDnVSHagEKF57xflvk1/vRuF/ydBEi3oOcy12llJXMboPf8LYv8XbF19TvQQv6O+isaBAtqLGwPYTOrDci27KiKfMjtIDe3twbaK6fQUztQUR2+QLZH5D9ex9YbGaforPvRwDMrIN2qFvQXH0BoJRyUynlNg9lj5nZhy73g17mIb9+nl5hP69ovmG/g8yknm9AE+XFrvtPITYfzKSnv8J0evrIXzx7jEqmiBDQFU/3LtpdhdGdoNJF30aDvJ3qyfyOjNkdyMB+7R18Cnmv49RQQ9C1DRnPY96eX12OoKeHAY60E1Q66hTyuLZSCQUd/z3s9Y41dUbYb6q5Hx5tBxFIghIcdY1Sd16TTd5R5JF96/IEK3AEKcZJKvEgQorn0GRtKeLd1PvYjRjVSJ6nEgWiDyeRM/EElUwSMr9GJaVE2OgKMvC/ML0/QoblyDhFf5/xcT/kZe5GhJCzXtZl7/sYl1G0aK71cW/7a4pq5OMVhgjTdtPlJ9EufDEyon80zyMKEG0LosIi5PRMNOV0fEyOIqPTjsFv3q+xG//en73uaaOebciIPkkNTcUB/akIuSO9j7DbRbSbi7Ze82fbqNT2tr3nPF2cN36HDKdRaf4nXOYhFCKc8j5a2pQ/4e35weXaiXQw6O3HkMO1Ds3NTUhPtnvbfvS2HETzMHR4N5rfnyADew3Zhp1o4TiA9LSDdCb09yzSnzGXL0Kou4Cnm7BZHBMcoLKNP/eyhqlnpqddjiCCDFPnXBBETiM9bmVvQ38jje1cQyXRXHIZ2lcCYsf9DdVhDllPeDvCyQj7uYIakj6CFpijaMG7AGz2dDcjZ/Aq0on1aFcbrw9dpYb7NqOdmaFoyl5v+3G0e11Npf5/BTzctPE9H5eFvdad/NZfIpFI9ClKKR0zu7V3yhsb+QmlRCKRSPQ1+vYTSqWU1Ygp0uInPwT8u3zPUWmqgcNm9tK/KNt9iHLcYtzMHvXnW/EX7xpsMbMd/McopbxJPcQeQs5IMP5A5wururJ9bGZvXUf5c8rfq7/mWG+rD4MorDGOwi0Ar5rZ/pk5Zy3rS6bH5wHWmdnwbOk9z5zaMB/9+ye66q9xdB+2AzxuZhd65b8RcT3j6vm6bc2g//7c3Juzfs2zLlDo8G5ml/1/v5uC/JuPRCKRSPQ5MvSXSCQSib5GLlSJRCKR6GvkQpVIJBKJvkYuVIlEIpHoa/wJ1vY3VH3l74cAAAAASUVORK5CYII=\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "plt.scatter(files,accuracy_scores)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 283
        },
        "id": "4heStmSXI6cR",
        "outputId": "4366605c-2987-4ec4-e3b6-e338e0a67253"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<matplotlib.collections.PathCollection at 0x7fd6693e4f10>"
            ]
          },
          "metadata": {},
          "execution_count": 15
        },
        {
          "output_type": "display_data",
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "6rqRQu-uQx-t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "bTMZ-vgdQx1x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "automation(['combined_pssm2.csv'])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_VShyU9MQxob",
        "outputId": "6fe8e494-d265-4898-8c5c-273aa9a97887"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "\n",
            "Feature Name:  combined_pssm2.csv\n",
            "\n",
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[11:14:04] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.88       772\n",
            "           1       0.84      0.89      0.86       825\n",
            "           2       0.92      0.91      0.91      1293\n",
            "           3       0.80      0.77      0.78      1021\n",
            "\n",
            "    accuracy                           0.86      3911\n",
            "   macro avg       0.86      0.86      0.86      3911\n",
            "weighted avg       0.86      0.86      0.86      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 674   14   25   59]\n",
            " [  13  736    8   68]\n",
            " [  18   23 1179   73]\n",
            " [  58  106   75  782]]\n",
            "\n",
            "\n",
            "Accuracy: 0.8619278956788545\n",
            "\n",
            "\n",
            "Precision: [0.88335518 0.83731513 0.91608392 0.79633401]\n",
            "\n",
            "Recall: [0.87305699 0.89212121 0.91183295 0.76591577]\n",
            "\n",
            "F1 score: [0.8781759  0.86384977 0.91395349 0.78082876]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('combined_pssm2.csv')\n",
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2KCF_qXUR1jD",
        "outputId": "8708550a-69f8-4be1-fbe5-5e41967491b9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13035 entries, 0 to 13034\n",
            "Columns: 2501 entries, V1 to class\n",
            "dtypes: float64(2500), object(1)\n",
            "memory usage: 248.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "I3LNYGg7TU--",
        "outputId": "7bdd63c0-eb2d-4457-8fe5-f2971cb00672"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-91c4f785-5910-410a-8178-5969abc7d784\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>V11</th>\n",
              "      <th>V12</th>\n",
              "      <th>V13</th>\n",
              "      <th>V14</th>\n",
              "      <th>V15</th>\n",
              "      <th>V16</th>\n",
              "      <th>V17</th>\n",
              "      <th>V18</th>\n",
              "      <th>V19</th>\n",
              "      <th>V20</th>\n",
              "      <th>V21</th>\n",
              "      <th>V22</th>\n",
              "      <th>V23</th>\n",
              "      <th>V24</th>\n",
              "      <th>V25</th>\n",
              "      <th>V26</th>\n",
              "      <th>V27</th>\n",
              "      <th>V28</th>\n",
              "      <th>V29</th>\n",
              "      <th>V30</th>\n",
              "      <th>V31</th>\n",
              "      <th>V32</th>\n",
              "      <th>V33</th>\n",
              "      <th>V34</th>\n",
              "      <th>V35</th>\n",
              "      <th>V36</th>\n",
              "      <th>V37</th>\n",
              "      <th>V38</th>\n",
              "      <th>V39</th>\n",
              "      <th>V40</th>\n",
              "      <th>...</th>\n",
              "      <th>V522</th>\n",
              "      <th>V523</th>\n",
              "      <th>V524</th>\n",
              "      <th>V525</th>\n",
              "      <th>V526</th>\n",
              "      <th>V527</th>\n",
              "      <th>V528</th>\n",
              "      <th>V529</th>\n",
              "      <th>V530</th>\n",
              "      <th>V531</th>\n",
              "      <th>V532</th>\n",
              "      <th>V533</th>\n",
              "      <th>V534</th>\n",
              "      <th>V535</th>\n",
              "      <th>V536</th>\n",
              "      <th>V537</th>\n",
              "      <th>V538</th>\n",
              "      <th>V539</th>\n",
              "      <th>V540</th>\n",
              "      <th>V541</th>\n",
              "      <th>V542</th>\n",
              "      <th>V543</th>\n",
              "      <th>V544</th>\n",
              "      <th>V545</th>\n",
              "      <th>V546</th>\n",
              "      <th>V547</th>\n",
              "      <th>V548</th>\n",
              "      <th>V549</th>\n",
              "      <th>V550</th>\n",
              "      <th>V551</th>\n",
              "      <th>V552</th>\n",
              "      <th>V553</th>\n",
              "      <th>V554</th>\n",
              "      <th>V555</th>\n",
              "      <th>V556</th>\n",
              "      <th>V557</th>\n",
              "      <th>V558</th>\n",
              "      <th>V559</th>\n",
              "      <th>V560</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13030</th>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.5481</td>\n",
              "      <td>0.1346</td>\n",
              "      <td>0.5385</td>\n",
              "      <td>1.2212</td>\n",
              "      <td>0.1635</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.6058</td>\n",
              "      <td>0.5577</td>\n",
              "      <td>0.9712</td>\n",
              "      <td>0.7596</td>\n",
              "      <td>0.1827</td>\n",
              "      <td>0.4808</td>\n",
              "      <td>1.0769</td>\n",
              "      <td>0.4808</td>\n",
              "      <td>-0.0962</td>\n",
              "      <td>0.3846</td>\n",
              "      <td>1.4712</td>\n",
              "      <td>0.9135</td>\n",
              "      <td>0.8077</td>\n",
              "      <td>0.4423</td>\n",
              "      <td>1.4615</td>\n",
              "      <td>1.5385</td>\n",
              "      <td>1.7404</td>\n",
              "      <td>1.8077</td>\n",
              "      <td>1.0000</td>\n",
              "      <td>0.8558</td>\n",
              "      <td>2.2500</td>\n",
              "      <td>1.9615</td>\n",
              "      <td>1.0192</td>\n",
              "      <td>0.9327</td>\n",
              "      <td>0.8558</td>\n",
              "      <td>0.5192</td>\n",
              "      <td>1.8365</td>\n",
              "      <td>1.6635</td>\n",
              "      <td>0.4808</td>\n",
              "      <td>0.3942</td>\n",
              "      <td>2.6827</td>\n",
              "      <td>1.7596</td>\n",
              "      <td>0.5577</td>\n",
              "      <td>...</td>\n",
              "      <td>12073.540</td>\n",
              "      <td>8324.661</td>\n",
              "      <td>9009.777</td>\n",
              "      <td>10367.794</td>\n",
              "      <td>10741.985</td>\n",
              "      <td>11347.963</td>\n",
              "      <td>11845.120</td>\n",
              "      <td>9894.210</td>\n",
              "      <td>9790.654</td>\n",
              "      <td>9604.034</td>\n",
              "      <td>9811.387</td>\n",
              "      <td>8249.689</td>\n",
              "      <td>11333.534</td>\n",
              "      <td>9068.364</td>\n",
              "      <td>11134.687</td>\n",
              "      <td>10944.832</td>\n",
              "      <td>10786.400</td>\n",
              "      <td>10444.737</td>\n",
              "      <td>10148.434</td>\n",
              "      <td>8691.373</td>\n",
              "      <td>10141.109</td>\n",
              "      <td>11572.973</td>\n",
              "      <td>9722.879</td>\n",
              "      <td>11612.456</td>\n",
              "      <td>9926.958</td>\n",
              "      <td>10667.882</td>\n",
              "      <td>10279.962</td>\n",
              "      <td>11277.469</td>\n",
              "      <td>8096.723</td>\n",
              "      <td>9646.457</td>\n",
              "      <td>9915.719</td>\n",
              "      <td>9176.061</td>\n",
              "      <td>10704.678</td>\n",
              "      <td>11398.771</td>\n",
              "      <td>10360.027</td>\n",
              "      <td>11108.060</td>\n",
              "      <td>11440.514</td>\n",
              "      <td>9073.175</td>\n",
              "      <td>9461.005</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13031</th>\n",
              "      <td>1.1848</td>\n",
              "      <td>1.5638</td>\n",
              "      <td>1.4769</td>\n",
              "      <td>2.9390</td>\n",
              "      <td>3.4769</td>\n",
              "      <td>2.3142</td>\n",
              "      <td>2.5730</td>\n",
              "      <td>1.2902</td>\n",
              "      <td>1.6839</td>\n",
              "      <td>3.4455</td>\n",
              "      <td>3.1460</td>\n",
              "      <td>1.9963</td>\n",
              "      <td>2.6636</td>\n",
              "      <td>2.8447</td>\n",
              "      <td>3.0092</td>\n",
              "      <td>1.0074</td>\n",
              "      <td>1.7468</td>\n",
              "      <td>3.1701</td>\n",
              "      <td>2.5102</td>\n",
              "      <td>3.0813</td>\n",
              "      <td>2.1738</td>\n",
              "      <td>8.1054</td>\n",
              "      <td>6.4325</td>\n",
              "      <td>8.6599</td>\n",
              "      <td>9.4399</td>\n",
              "      <td>6.8189</td>\n",
              "      <td>7.7468</td>\n",
              "      <td>6.3272</td>\n",
              "      <td>7.0518</td>\n",
              "      <td>6.5915</td>\n",
              "      <td>7.2255</td>\n",
              "      <td>7.7819</td>\n",
              "      <td>5.6081</td>\n",
              "      <td>8.3327</td>\n",
              "      <td>9.5360</td>\n",
              "      <td>3.7708</td>\n",
              "      <td>4.0296</td>\n",
              "      <td>11.1590</td>\n",
              "      <td>8.2865</td>\n",
              "      <td>5.7579</td>\n",
              "      <td>...</td>\n",
              "      <td>285189.563</td>\n",
              "      <td>270210.377</td>\n",
              "      <td>284524.032</td>\n",
              "      <td>285760.470</td>\n",
              "      <td>289639.180</td>\n",
              "      <td>279030.201</td>\n",
              "      <td>291426.924</td>\n",
              "      <td>281617.029</td>\n",
              "      <td>297360.561</td>\n",
              "      <td>289209.756</td>\n",
              "      <td>303970.588</td>\n",
              "      <td>305222.932</td>\n",
              "      <td>263991.587</td>\n",
              "      <td>312918.132</td>\n",
              "      <td>274252.516</td>\n",
              "      <td>289423.875</td>\n",
              "      <td>286208.487</td>\n",
              "      <td>250260.180</td>\n",
              "      <td>258445.318</td>\n",
              "      <td>279113.099</td>\n",
              "      <td>303599.930</td>\n",
              "      <td>277476.759</td>\n",
              "      <td>295937.265</td>\n",
              "      <td>286764.545</td>\n",
              "      <td>269295.107</td>\n",
              "      <td>299847.814</td>\n",
              "      <td>262075.343</td>\n",
              "      <td>272063.211</td>\n",
              "      <td>273705.950</td>\n",
              "      <td>291340.219</td>\n",
              "      <td>262958.914</td>\n",
              "      <td>285735.507</td>\n",
              "      <td>307587.675</td>\n",
              "      <td>299389.564</td>\n",
              "      <td>316437.921</td>\n",
              "      <td>294029.876</td>\n",
              "      <td>288840.762</td>\n",
              "      <td>287647.980</td>\n",
              "      <td>303895.461</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13032</th>\n",
              "      <td>-1.1078</td>\n",
              "      <td>0.8627</td>\n",
              "      <td>0.8627</td>\n",
              "      <td>1.2255</td>\n",
              "      <td>1.7255</td>\n",
              "      <td>0.2451</td>\n",
              "      <td>1.0294</td>\n",
              "      <td>0.6765</td>\n",
              "      <td>0.3824</td>\n",
              "      <td>0.9706</td>\n",
              "      <td>1.2059</td>\n",
              "      <td>0.4804</td>\n",
              "      <td>1.4804</td>\n",
              "      <td>1.5588</td>\n",
              "      <td>0.2353</td>\n",
              "      <td>-0.5294</td>\n",
              "      <td>0.2157</td>\n",
              "      <td>2.9706</td>\n",
              "      <td>0.4216</td>\n",
              "      <td>0.5686</td>\n",
              "      <td>1.4804</td>\n",
              "      <td>3.0098</td>\n",
              "      <td>4.9804</td>\n",
              "      <td>4.7353</td>\n",
              "      <td>6.2843</td>\n",
              "      <td>2.7059</td>\n",
              "      <td>3.1961</td>\n",
              "      <td>6.5490</td>\n",
              "      <td>4.1961</td>\n",
              "      <td>1.7353</td>\n",
              "      <td>2.7451</td>\n",
              "      <td>3.2255</td>\n",
              "      <td>2.9314</td>\n",
              "      <td>4.6176</td>\n",
              "      <td>4.1373</td>\n",
              "      <td>3.0196</td>\n",
              "      <td>2.0980</td>\n",
              "      <td>7.1863</td>\n",
              "      <td>4.0098</td>\n",
              "      <td>1.3725</td>\n",
              "      <td>...</td>\n",
              "      <td>9383.070</td>\n",
              "      <td>8895.248</td>\n",
              "      <td>7725.012</td>\n",
              "      <td>9000.746</td>\n",
              "      <td>9148.814</td>\n",
              "      <td>9804.565</td>\n",
              "      <td>7810.699</td>\n",
              "      <td>9347.173</td>\n",
              "      <td>8952.810</td>\n",
              "      <td>9252.000</td>\n",
              "      <td>9572.844</td>\n",
              "      <td>9863.918</td>\n",
              "      <td>11063.819</td>\n",
              "      <td>10172.950</td>\n",
              "      <td>9611.596</td>\n",
              "      <td>10256.145</td>\n",
              "      <td>8807.302</td>\n",
              "      <td>8563.792</td>\n",
              "      <td>8221.450</td>\n",
              "      <td>7630.566</td>\n",
              "      <td>7724.258</td>\n",
              "      <td>10075.549</td>\n",
              "      <td>9068.439</td>\n",
              "      <td>11393.996</td>\n",
              "      <td>10420.071</td>\n",
              "      <td>9136.098</td>\n",
              "      <td>8969.857</td>\n",
              "      <td>8553.755</td>\n",
              "      <td>9134.992</td>\n",
              "      <td>8200.230</td>\n",
              "      <td>10471.817</td>\n",
              "      <td>8660.796</td>\n",
              "      <td>10948.821</td>\n",
              "      <td>11523.082</td>\n",
              "      <td>11647.923</td>\n",
              "      <td>9441.705</td>\n",
              "      <td>9310.609</td>\n",
              "      <td>8159.080</td>\n",
              "      <td>8141.003</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13033</th>\n",
              "      <td>-1.3900</td>\n",
              "      <td>0.6900</td>\n",
              "      <td>0.4500</td>\n",
              "      <td>1.4400</td>\n",
              "      <td>1.7000</td>\n",
              "      <td>0.5700</td>\n",
              "      <td>0.8200</td>\n",
              "      <td>0.8800</td>\n",
              "      <td>0.3700</td>\n",
              "      <td>1.9300</td>\n",
              "      <td>1.8400</td>\n",
              "      <td>0.4500</td>\n",
              "      <td>1.1300</td>\n",
              "      <td>1.5400</td>\n",
              "      <td>0.7300</td>\n",
              "      <td>-0.2600</td>\n",
              "      <td>0.2500</td>\n",
              "      <td>2.6000</td>\n",
              "      <td>0.6200</td>\n",
              "      <td>0.8800</td>\n",
              "      <td>1.2300</td>\n",
              "      <td>2.4500</td>\n",
              "      <td>4.3000</td>\n",
              "      <td>4.3200</td>\n",
              "      <td>6.4000</td>\n",
              "      <td>2.3200</td>\n",
              "      <td>2.5200</td>\n",
              "      <td>5.8000</td>\n",
              "      <td>3.6100</td>\n",
              "      <td>2.3900</td>\n",
              "      <td>3.1100</td>\n",
              "      <td>2.3700</td>\n",
              "      <td>3.9200</td>\n",
              "      <td>5.0200</td>\n",
              "      <td>3.6200</td>\n",
              "      <td>3.0300</td>\n",
              "      <td>2.4200</td>\n",
              "      <td>7.2400</td>\n",
              "      <td>4.1600</td>\n",
              "      <td>1.7000</td>\n",
              "      <td>...</td>\n",
              "      <td>9511.905</td>\n",
              "      <td>7564.112</td>\n",
              "      <td>5991.858</td>\n",
              "      <td>9267.087</td>\n",
              "      <td>8277.213</td>\n",
              "      <td>10437.879</td>\n",
              "      <td>7109.106</td>\n",
              "      <td>9173.084</td>\n",
              "      <td>8229.919</td>\n",
              "      <td>9244.719</td>\n",
              "      <td>8614.721</td>\n",
              "      <td>9604.695</td>\n",
              "      <td>9501.081</td>\n",
              "      <td>9808.890</td>\n",
              "      <td>8292.907</td>\n",
              "      <td>9639.898</td>\n",
              "      <td>8867.434</td>\n",
              "      <td>7694.812</td>\n",
              "      <td>7912.598</td>\n",
              "      <td>6797.708</td>\n",
              "      <td>7622.866</td>\n",
              "      <td>8815.197</td>\n",
              "      <td>8374.518</td>\n",
              "      <td>10476.970</td>\n",
              "      <td>9327.930</td>\n",
              "      <td>9001.186</td>\n",
              "      <td>8467.499</td>\n",
              "      <td>8537.783</td>\n",
              "      <td>8385.003</td>\n",
              "      <td>7877.795</td>\n",
              "      <td>10565.884</td>\n",
              "      <td>8806.434</td>\n",
              "      <td>10773.072</td>\n",
              "      <td>10456.661</td>\n",
              "      <td>11102.445</td>\n",
              "      <td>8963.299</td>\n",
              "      <td>8891.549</td>\n",
              "      <td>7769.568</td>\n",
              "      <td>7952.767</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13034</th>\n",
              "      <td>0.2966</td>\n",
              "      <td>0.6949</td>\n",
              "      <td>0.7288</td>\n",
              "      <td>0.8136</td>\n",
              "      <td>0.9492</td>\n",
              "      <td>0.4237</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>1.5000</td>\n",
              "      <td>1.0508</td>\n",
              "      <td>0.0254</td>\n",
              "      <td>0.1610</td>\n",
              "      <td>0.5424</td>\n",
              "      <td>0.1017</td>\n",
              "      <td>0.9407</td>\n",
              "      <td>1.0763</td>\n",
              "      <td>0.2881</td>\n",
              "      <td>-0.1610</td>\n",
              "      <td>1.7288</td>\n",
              "      <td>0.8559</td>\n",
              "      <td>-0.0932</td>\n",
              "      <td>0.9153</td>\n",
              "      <td>1.6864</td>\n",
              "      <td>0.1949</td>\n",
              "      <td>0.8390</td>\n",
              "      <td>2.5339</td>\n",
              "      <td>0.2542</td>\n",
              "      <td>0.7881</td>\n",
              "      <td>2.1864</td>\n",
              "      <td>1.9407</td>\n",
              "      <td>1.1356</td>\n",
              "      <td>1.7034</td>\n",
              "      <td>1.0508</td>\n",
              "      <td>0.8983</td>\n",
              "      <td>2.6864</td>\n",
              "      <td>2.5085</td>\n",
              "      <td>0.1780</td>\n",
              "      <td>-0.4746</td>\n",
              "      <td>4.0678</td>\n",
              "      <td>2.2881</td>\n",
              "      <td>0.6949</td>\n",
              "      <td>...</td>\n",
              "      <td>14905.406</td>\n",
              "      <td>12894.636</td>\n",
              "      <td>12586.903</td>\n",
              "      <td>14565.620</td>\n",
              "      <td>12991.503</td>\n",
              "      <td>14405.129</td>\n",
              "      <td>14284.313</td>\n",
              "      <td>13785.671</td>\n",
              "      <td>14268.792</td>\n",
              "      <td>13302.212</td>\n",
              "      <td>13332.044</td>\n",
              "      <td>12749.355</td>\n",
              "      <td>14627.757</td>\n",
              "      <td>11696.120</td>\n",
              "      <td>14792.451</td>\n",
              "      <td>13010.033</td>\n",
              "      <td>12525.477</td>\n",
              "      <td>13947.020</td>\n",
              "      <td>12673.456</td>\n",
              "      <td>13955.177</td>\n",
              "      <td>11890.624</td>\n",
              "      <td>15401.463</td>\n",
              "      <td>11058.269</td>\n",
              "      <td>14172.514</td>\n",
              "      <td>13584.986</td>\n",
              "      <td>12807.883</td>\n",
              "      <td>14722.963</td>\n",
              "      <td>12748.542</td>\n",
              "      <td>13805.162</td>\n",
              "      <td>12068.708</td>\n",
              "      <td>12158.411</td>\n",
              "      <td>14458.614</td>\n",
              "      <td>16017.375</td>\n",
              "      <td>15627.743</td>\n",
              "      <td>14401.645</td>\n",
              "      <td>13713.625</td>\n",
              "      <td>13803.527</td>\n",
              "      <td>12025.509</td>\n",
              "      <td>11144.905</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 2501 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-91c4f785-5910-410a-8178-5969abc7d784')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-91c4f785-5910-410a-8178-5969abc7d784 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-91c4f785-5910-410a-8178-5969abc7d784');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "           V1      V2      V3  ...        V559        V560  class\n",
              "13030  0.3654  0.5481  0.1346  ...    9073.175    9461.005      b\n",
              "13031  1.1848  1.5638  1.4769  ...  287647.980  303895.461      d\n",
              "13032 -1.1078  0.8627  0.8627  ...    8159.080    8141.003      d\n",
              "13033 -1.3900  0.6900  0.4500  ...    7769.568    7952.767      d\n",
              "13034  0.2966  0.6949  0.7288  ...   12025.509   11144.905      b\n",
              "\n",
              "[5 rows x 2501 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "uIna54qIUMGB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#Savinfg model in pickle file\n"
      ],
      "metadata": {
        "id": "OXxWV_RjQxS3"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "akU01GWGkx7x"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def saveModel(data):\n",
        "  X= data.iloc[:,:-1].values\n",
        "  y= data.iloc[:,-1].values\n",
        "  le = LabelEncoder()\n",
        "  print(y)\n",
        "  y= le.fit_transform(y) \n",
        "  print(y)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 5)\n",
        "\n",
        "  model = XGBClassifier(tree_method='gpu_hist',use_label_encoder=False)\n",
        "  model.fit(X_train, y_train)\n",
        "  pickle.dump(model, open('model.pkl','wb'))\n",
        "\n",
        "  y_pred = model.predict(X_test)\n",
        "\n",
        "  print('\\nClassification report:\\n', classification_report(y_test,y_pred))\n",
        "  print('Confusion matrix: \\n', confusion_matrix(y_test,y_pred))\n",
        "\n",
        "  accuracy = accuracy_score(y_test,y_pred)\n",
        "  accuracy_scores.append(accuracy)\n",
        "  print(\"\\n\\nAccuracy:\",accuracy_score(y_test, y_pred))\n",
        "\n",
        "  print(\"\\n\\nPrecision:\",precision_score(y_test, y_pred, average=None))\n",
        "  print(\"\\nRecall:\",recall_score(y_test, y_pred, average=None))\n",
        "  print(\"\\nF1 score:\",f1_score(y_test, y_pred, average=None))"
      ],
      "metadata": {
        "id": "UweQGfy3Qw0l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv('combined_pssm2.csv')\n"
      ],
      "metadata": {
        "id": "qhaNNW1TR6Y2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= df.iloc[:,:-1]\n",
        "y= df.iloc[:,-1]"
      ],
      "metadata": {
        "id": "i1dXpEjtR-sA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_model=pickle.load(open(\"model.pkl\",\"rb\"))\n",
        "print(load_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yn1BBZY4k8AA",
        "outputId": "7a1b2e25-76ee-4f5b-a0e0-5667959aa7bb"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
            "              gamma=0, gpu_id=0, importance_type=None,\n",
            "              interaction_constraints='', learning_rate=0.300000012,\n",
            "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
            "              monotone_constraints='()', n_estimators=100, n_jobs=2,\n",
            "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
            "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
            "              subsample=1, tree_method='gpu_hist', use_label_encoder=False,\n",
            "              validate_parameters=1, verbosity=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.iloc[0,:-1].values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uKy1rEB3mXQ9",
        "outputId": "94132488-6463-4e5b-faea-0e5d4286ccd0"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0.9877, 0.7669, 0.7147, ..., 94187.106, 96137.087, 101893.312],\n",
              "      dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "  X= df.iloc[:,:-1]\n",
        "  y= df.iloc[:,-1]\n",
        "  print(X)\n",
        "  print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5bsC2ZJznWl5",
        "outputId": "b9cb48d0-485f-4d41-98ee-1c585437f453"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           V1      V2      V3      V4      V5      V6      V7      V8      V9  \\\n",
            "0      0.9877  0.7669  0.7147  0.7791  2.3712  0.4663  0.5644  1.5337  1.0644   \n",
            "1      0.1183  0.4592  0.4479  0.5577  0.4423  0.2789  0.3775  0.6761  0.6141   \n",
            "2      0.6753  0.9351  1.0390  1.8442  0.5844  0.8182  1.0649  1.6623  0.9870   \n",
            "3     -0.0625  0.4167  0.7083  0.6771  0.5104  0.1042  0.3021  0.2708  0.9688   \n",
            "4      2.0909  4.2576  4.5606  5.7576  4.9848  3.6364  4.7273  4.2121  5.4242   \n",
            "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
            "13030  0.3654  0.5481  0.1346  0.5385  1.2212  0.1635  0.1442  0.6058  0.5577   \n",
            "13031  1.1848  1.5638  1.4769  2.9390  3.4769  2.3142  2.5730  1.2902  1.6839   \n",
            "13032 -1.1078  0.8627  0.8627  1.2255  1.7255  0.2451  1.0294  0.6765  0.3824   \n",
            "13033 -1.3900  0.6900  0.4500  1.4400  1.7000  0.5700  0.8200  0.8800  0.3700   \n",
            "13034  0.2966  0.6949  0.7288  0.8136  0.9492  0.4237  0.5000  1.5000  1.0508   \n",
            "\n",
            "          V10  ...        V551        V552        V553        V554  \\\n",
            "0      2.1135  ...   95877.142  114070.624  108091.136  114669.085   \n",
            "1      0.2000  ...  120356.604  137325.433  131197.669  135505.009   \n",
            "2      0.0649  ...    4743.110    5949.595    5316.943    5636.386   \n",
            "3      0.3125  ...    7587.045    8391.055    8743.541    7549.078   \n",
            "4      3.4697  ...    3082.977    4683.468    4057.229    4114.765   \n",
            "...       ...  ...         ...         ...         ...         ...   \n",
            "13030  0.9712  ...    9646.457    9915.719    9176.061   10704.678   \n",
            "13031  3.4455  ...  291340.219  262958.914  285735.507  307587.675   \n",
            "13032  0.9706  ...    8200.230   10471.817    8660.796   10948.821   \n",
            "13033  1.9300  ...    7877.795   10565.884    8806.434   10773.072   \n",
            "13034  0.0254  ...   12068.708   12158.411   14458.614   16017.375   \n",
            "\n",
            "             V555        V556        V557        V558        V559        V560  \n",
            "0       99283.599  108429.814   99375.890   94187.106   96137.087  101893.312  \n",
            "1      117565.612  127873.474  123841.017  118688.798  118811.827  133332.085  \n",
            "2        5225.542    6527.143    5140.157    5661.591    5220.387    4293.378  \n",
            "3        9642.123    9897.976    8942.383    9205.542    9950.298    7470.748  \n",
            "4        3349.771    4024.599    4237.269    3284.416    3987.280    3333.758  \n",
            "...           ...         ...         ...         ...         ...         ...  \n",
            "13030   11398.771   10360.027   11108.060   11440.514    9073.175    9461.005  \n",
            "13031  299389.564  316437.921  294029.876  288840.762  287647.980  303895.461  \n",
            "13032   11523.082   11647.923    9441.705    9310.609    8159.080    8141.003  \n",
            "13033   10456.661   11102.445    8963.299    8891.549    7769.568    7952.767  \n",
            "13034   15627.743   14401.645   13713.625   13803.527   12025.509   11144.905  \n",
            "\n",
            "[13035 rows x 2500 columns]\n",
            "0        d\n",
            "1        d\n",
            "2        d\n",
            "3        d\n",
            "4        a\n",
            "        ..\n",
            "13030    b\n",
            "13031    d\n",
            "13032    d\n",
            "13033    d\n",
            "13034    b\n",
            "Name: class, Length: 13035, dtype: object\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "le = LabelEncoder()\n",
        "print(y)\n",
        "y= le.fit_transform(y) \n",
        "print(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 5)\n",
        "\n",
        "model = XGBClassifier(tree_method='gpu_hist',use_label_encoder=False)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2kiBeQ6cnmA8",
        "outputId": "662bc27d-582d-4b70-fe20-1cd7cecc8772"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "0        d\n",
            "1        d\n",
            "2        d\n",
            "3        d\n",
            "4        a\n",
            "        ..\n",
            "13030    b\n",
            "13031    d\n",
            "13032    d\n",
            "13033    d\n",
            "13034    b\n",
            "Name: class, Length: 13035, dtype: object\n",
            "[3 3 3 ... 3 3 1]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Tc_ahJx4nl9E",
        "outputId": "c2f925d1-05c8-4c57-cead-7caede8e5649"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(9124, 2500)"
            ]
          },
          "metadata": {},
          "execution_count": 57
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.fit(X_train, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9vbrk62ynlzN",
        "outputId": "1d858770-f0a8-4ee9-db7d-1726dac3707d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[16:15:14] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
              "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
              "              gamma=0, gpu_id=0, importance_type=None,\n",
              "              interaction_constraints='', learning_rate=0.300000012,\n",
              "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
              "              monotone_constraints='()', n_estimators=100, n_jobs=2,\n",
              "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
              "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
              "              subsample=1, tree_method='gpu_hist', use_label_encoder=False,\n",
              "              validate_parameters=1, verbosity=None)"
            ]
          },
          "metadata": {},
          "execution_count": 58
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        " y_pred = model.predict(X_test)\n",
        "\n",
        "print('\\nClassification report:\\n', classification_report(y_test,y_pred))\n",
        "print('Confusion matrix: \\n', confusion_matrix(y_test,y_pred))\n",
        "\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "accuracy_scores.append(accuracy)\n",
        "print(\"\\n\\nAccuracy:\",accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"\\n\\nPrecision:\",precision_score(y_test, y_pred, average=None))\n",
        "print(\"\\nRecall:\",recall_score(y_test, y_pred, average=None))\n",
        "print(\"\\nF1 score:\",f1_score(y_test, y_pred, average=None))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "MFxkxCT7t4Ah",
        "outputId": "8d4b77f1-3ecc-4618-c176-04772b97c371"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.88      0.87      0.88       772\n",
            "           1       0.84      0.89      0.86       825\n",
            "           2       0.92      0.91      0.91      1293\n",
            "           3       0.80      0.77      0.78      1021\n",
            "\n",
            "    accuracy                           0.86      3911\n",
            "   macro avg       0.86      0.86      0.86      3911\n",
            "weighted avg       0.86      0.86      0.86      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 674   14   25   59]\n",
            " [  13  736    8   68]\n",
            " [  18   23 1179   73]\n",
            " [  58  106   75  782]]\n",
            "\n",
            "\n",
            "Accuracy: 0.8619278956788545\n",
            "\n",
            "\n",
            "Precision: [0.88335518 0.83731513 0.91608392 0.79633401]\n",
            "\n",
            "Recall: [0.87305699 0.89212121 0.91183295 0.76591577]\n",
            "\n",
            "F1 score: [0.8781759  0.86384977 0.91395349 0.78082876]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "pickle.dump(model, open(\"model.dat\", \"wb\"))"
      ],
      "metadata": {
        "id": "dR9k2zsPtrnr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "load_model = pickle.load(open(\"model.dat\",\"rb\"))\n",
        "print(load_model)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GfPfzIvGuHmb",
        "outputId": "19b5e494-61c5-48cc-87bb-02ac44cf20a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "XGBClassifier(base_score=0.5, booster='gbtree', colsample_bylevel=1,\n",
            "              colsample_bynode=1, colsample_bytree=1, enable_categorical=False,\n",
            "              gamma=0, gpu_id=0, importance_type=None,\n",
            "              interaction_constraints='', learning_rate=0.300000012,\n",
            "              max_delta_step=0, max_depth=6, min_child_weight=1, missing=nan,\n",
            "              monotone_constraints='()', n_estimators=100, n_jobs=2,\n",
            "              num_parallel_tree=1, objective='multi:softprob', predictor='auto',\n",
            "              random_state=0, reg_alpha=0, reg_lambda=1, scale_pos_weight=None,\n",
            "              subsample=1, tree_method='gpu_hist', use_label_encoder=False,\n",
            "              validate_parameters=1, verbosity=None)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(df.iloc[0,:-1])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "j6Z9VEequThR",
        "outputId": "aca84e17-9b9d-43d1-92e0-eaef65afd2bd"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.series.Series"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "df.info()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lOuqsYMJux2p",
        "outputId": "ec6a637d-7c33-4e41-8157-010af5d0c4a6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 13035 entries, 0 to 13034\n",
            "Columns: 2501 entries, V1 to class\n",
            "dtypes: float64(2500), object(1)\n",
            "memory usage: 248.7+ MB\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "type(X_test)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ze62N2oevGgI",
        "outputId": "89ec8c8b-6d81-4b5b-90f5-ce08e6b52c0c"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "pandas.core.frame.DataFrame"
            ]
          },
          "metadata": {},
          "execution_count": 72
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cHhf6SSQxNAD",
        "outputId": "6067d82c-9a9d-4233-8bfe-641bbaba3092"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3911, 2500)"
            ]
          },
          "metadata": {},
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tmp=df.iloc[0,:-1]\n",
        "type(tmp)\n",
        "result=pd.DataFrame([tmp])\n",
        "print(result)\n",
        "print(type(result))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sbCj8oDtu7b0",
        "outputId": "70c4cebe-e33f-45d6-db93-8ae9407c4347"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "       V1      V2      V3      V4      V5      V6      V7      V8      V9  \\\n",
            "0  0.9877  0.7669  0.7147  0.7791  2.3712  0.4663  0.5644  1.5337  1.0644   \n",
            "\n",
            "      V10  ...       V551        V552        V553        V554       V555  \\\n",
            "0  2.1135  ...  95877.142  114070.624  108091.136  114669.085  99283.599   \n",
            "\n",
            "         V556      V557       V558       V559        V560  \n",
            "0  108429.814  99375.89  94187.106  96137.087  101893.312  \n",
            "\n",
            "[1 rows x 2500 columns]\n",
            "<class 'pandas.core.frame.DataFrame'>\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "result.head()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 174
        },
        "id": "MNF5Jsk6wmPG",
        "outputId": "96878420-6261-49fb-9ce0-6ecdcf638d17"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "  <div id=\"df-f9400bf5-1519-4e76-b8ed-1ab1b49323d7\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V551</th>\n",
              "      <th>V552</th>\n",
              "      <th>V553</th>\n",
              "      <th>V554</th>\n",
              "      <th>V555</th>\n",
              "      <th>V556</th>\n",
              "      <th>V557</th>\n",
              "      <th>V558</th>\n",
              "      <th>V559</th>\n",
              "      <th>V560</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.9877</td>\n",
              "      <td>0.7669</td>\n",
              "      <td>0.7147</td>\n",
              "      <td>0.7791</td>\n",
              "      <td>2.3712</td>\n",
              "      <td>0.4663</td>\n",
              "      <td>0.5644</td>\n",
              "      <td>1.5337</td>\n",
              "      <td>1.0644</td>\n",
              "      <td>2.1135</td>\n",
              "      <td>...</td>\n",
              "      <td>95877.142</td>\n",
              "      <td>114070.624</td>\n",
              "      <td>108091.136</td>\n",
              "      <td>114669.085</td>\n",
              "      <td>99283.599</td>\n",
              "      <td>108429.814</td>\n",
              "      <td>99375.89</td>\n",
              "      <td>94187.106</td>\n",
              "      <td>96137.087</td>\n",
              "      <td>101893.312</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>1 rows × 2500 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-f9400bf5-1519-4e76-b8ed-1ab1b49323d7')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-f9400bf5-1519-4e76-b8ed-1ab1b49323d7 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-f9400bf5-1519-4e76-b8ed-1ab1b49323d7');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ],
            "text/plain": [
              "       V1      V2      V3      V4      V5      V6      V7      V8      V9  \\\n",
              "0  0.9877  0.7669  0.7147  0.7791  2.3712  0.4663  0.5644  1.5337  1.0644   \n",
              "\n",
              "      V10  ...       V551        V552        V553        V554       V555  \\\n",
              "0  2.1135  ...  95877.142  114070.624  108091.136  114669.085  99283.599   \n",
              "\n",
              "         V556      V557       V558       V559        V560  \n",
              "0  108429.814  99375.89  94187.106  96137.087  101893.312  \n",
              "\n",
              "[1 rows x 2500 columns]"
            ]
          },
          "metadata": {},
          "execution_count": 82
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "load_model.predict(result)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "wn4Y-a7vuHio",
        "outputId": "24a09dc8-97d4-49cd-c28d-d76a506a5a96"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([3])"
            ]
          },
          "metadata": {},
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "NAZhzfjPuHgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "N8WaHAnAoxqe",
        "outputId": "c9459bb0-9695-47b6-c164-4800f4348d7b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500,)"
            ]
          },
          "metadata": {},
          "execution_count": 36
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "IlSfcuHVo-5K",
        "outputId": "7e7fdd1f-ceac-4abc-98c7-e3f202440895"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[-2.46600000e-01,  2.12300000e-01, -1.09600000e-01, ...,\n",
              "         2.03364140e+04,  1.96093290e+04,  1.79076290e+04],\n",
              "       [ 3.96400000e-01, -2.70300000e-01, -3.34230000e+00, ...,\n",
              "         8.04879000e+03,  1.01401140e+04,  9.60064900e+03],\n",
              "       [ 2.35800000e-01,  6.03000000e-01,  4.74600000e-01, ...,\n",
              "         1.10699111e+05,  1.00982104e+05,  9.32007550e+04],\n",
              "       ...,\n",
              "       [ 2.54000000e-02,  1.01690000e+00,  8.30500000e-01, ...,\n",
              "         1.14204440e+04,  1.30540070e+04,  1.45302370e+04],\n",
              "       [-8.74000000e-02,  3.01000000e-01,  1.26200000e-01, ...,\n",
              "         9.53949300e+03,  9.25253000e+03,  8.65143700e+03],\n",
              "       [ 3.53000000e-02,  2.70600000e-01, -2.35000000e-02, ...,\n",
              "         5.76700200e+03,  5.67108400e+03,  5.06099400e+03]])"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(type(X_test))\n",
        "print(X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qF5KcPmtpAx6",
        "outputId": "241b8d99-9f4d-4d9b-fed9-ca5c9f552cf4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'numpy.ndarray'>\n",
            "(3911, 2500)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test[0]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9DlD4xHMpMmu",
        "outputId": "71bdf812-8da3-46b7-e04a-5a61688cbcf7"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([-2.4660000e-01,  2.1230000e-01, -1.0960000e-01, ...,\n",
              "        2.0336414e+04,  1.9609329e+04,  1.7907629e+04])"
            ]
          },
          "metadata": {},
          "execution_count": 43
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "y_pred=model.predict(X_test)"
      ],
      "metadata": {
        "id": "O7KvvSwqob1s"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "x=df.iloc[0,:-1].values\n",
        "x.shape\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sq49pQBLlI-4",
        "outputId": "b501b37f-be08-48c4-da57-f28789c8898a"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(2500,)"
            ]
          },
          "metadata": {},
          "execution_count": 34
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cols_when_model_builds = load_model.get_booster().feature_names\n",
        "print(cols_when_model_builds)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Agrz1S6Npz7h",
        "outputId": "8be313d9-5a20-47f9-d3ec-91b8ff8f99ed"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res=load_model.predict(X_test)"
      ],
      "metadata": {
        "id": "ttraJn6OmTHe"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y=x.reshape(-1,1)"
      ],
      "metadata": {
        "id": "skxbl945nEeT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0dlBKeQJqKLj",
        "outputId": "24db4fd5-3b04-4af3-b29d-043e9dfbdc27"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.9877],\n",
              "       [0.7669],\n",
              "       [0.7147],\n",
              "       ...,\n",
              "       [94187.106],\n",
              "       [96137.087],\n",
              "       [101893.312]], dtype=object)"
            ]
          },
          "metadata": {},
          "execution_count": 49
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "names=load_model.get_booster().feature_names\n",
        "print(names)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KQdsUdl1qbHI",
        "outputId": "396b96e2-7e5a-4333-8a4e-fdc4f8b600d2"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "None\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "O3hkqej7qfpb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def classModel3(data):\n",
        "  X= data.iloc[:,:-1].values\n",
        "  y= data.iloc[:,-1].values\n",
        "  \n",
        "  le = LabelEncoder()\n",
        "  print(y)\n",
        "  y= le.fit_transform(y) \n",
        "  print(y)\n",
        "\n",
        "  X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 5)\n",
        "\n",
        "  model = XGBClassifier(tree_method='gpu_hist',use_label_encoder=False)\n",
        "  model.fit(X_train, y_train)\n",
        "  y_pred = model.predict(X_test)\n",
        "  pickle.dump(model, open(\"model2.dat\", \"wb\"))\n",
        "\n",
        "  print('\\nClassification report:\\n', classification_report(y_test,y_pred))\n",
        "  print('Confusion matrix: \\n', confusion_matrix(y_test,y_pred))\n",
        "\n",
        "  accuracy = accuracy_score(y_test,y_pred)\n",
        "  #accuracy_scores.append(accuracy)\n",
        "  print(\"\\n\\nAccuracy:\",accuracy_score(y_test, y_pred))\n",
        "\n",
        "  print(\"\\n\\nPrecision:\",precision_score(y_test, y_pred, average=None))\n",
        "  print(\"\\nRecall:\",recall_score(y_test, y_pred, average=None))\n",
        "  print(\"\\nF1 score:\",f1_score(y_test, y_pred, average=None))"
      ],
      "metadata": {
        "id": "5wsgwiZQMOv5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df=pd.read_csv(\"combined_pssm3.csv\")\n",
        "df.tail()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 299
        },
        "id": "6yggSpFeMOsh",
        "outputId": "8ccfbe74-fd07-4301-ddc2-141382e5853d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "           V1      V2      V3      V4      V5      V6      V7      V8      V9  \\\n",
              "13030  0.3654  0.5481  0.1346  0.5385  1.2212  0.1635  0.1442  0.6058  0.5577   \n",
              "13031  1.1848  1.5638  1.4769  2.9390  3.4769  2.3142  2.5730  1.2902  1.6839   \n",
              "13032 -1.1078  0.8627  0.8627  1.2255  1.7255  0.2451  1.0294  0.6765  0.3824   \n",
              "13033 -1.3900  0.6900  0.4500  1.4400  1.7000  0.5700  0.8200  0.8800  0.3700   \n",
              "13034  0.2966  0.6949  0.7288  0.8136  0.9492  0.4237  0.5000  1.5000  1.0508   \n",
              "\n",
              "          V10  ...        V552        V553        V554        V555  \\\n",
              "13030  0.9712  ...    9915.719    9176.061   10704.678   11398.771   \n",
              "13031  3.4455  ...  262958.914  285735.507  307587.675  299389.564   \n",
              "13032  0.9706  ...   10471.817    8660.796   10948.821   11523.082   \n",
              "13033  1.9300  ...   10565.884    8806.434   10773.072   10456.661   \n",
              "13034  0.0254  ...   12158.411   14458.614   16017.375   15627.743   \n",
              "\n",
              "             V556        V557        V558        V559        V560  class  \n",
              "13030   10360.027   11108.060   11440.514    9073.175    9461.005      b  \n",
              "13031  316437.921  294029.876  288840.762  287647.980  303895.461      d  \n",
              "13032   11647.923    9441.705    9310.609    8159.080    8141.003      d  \n",
              "13033   11102.445    8963.299    8891.549    7769.568    7952.767      d  \n",
              "13034   14401.645   13713.625   13803.527   12025.509   11144.905      b  \n",
              "\n",
              "[5 rows x 1871 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-93e6d0fd-b503-40ca-b013-79878a5993bd\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>V1</th>\n",
              "      <th>V2</th>\n",
              "      <th>V3</th>\n",
              "      <th>V4</th>\n",
              "      <th>V5</th>\n",
              "      <th>V6</th>\n",
              "      <th>V7</th>\n",
              "      <th>V8</th>\n",
              "      <th>V9</th>\n",
              "      <th>V10</th>\n",
              "      <th>...</th>\n",
              "      <th>V552</th>\n",
              "      <th>V553</th>\n",
              "      <th>V554</th>\n",
              "      <th>V555</th>\n",
              "      <th>V556</th>\n",
              "      <th>V557</th>\n",
              "      <th>V558</th>\n",
              "      <th>V559</th>\n",
              "      <th>V560</th>\n",
              "      <th>class</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>13030</th>\n",
              "      <td>0.3654</td>\n",
              "      <td>0.5481</td>\n",
              "      <td>0.1346</td>\n",
              "      <td>0.5385</td>\n",
              "      <td>1.2212</td>\n",
              "      <td>0.1635</td>\n",
              "      <td>0.1442</td>\n",
              "      <td>0.6058</td>\n",
              "      <td>0.5577</td>\n",
              "      <td>0.9712</td>\n",
              "      <td>...</td>\n",
              "      <td>9915.719</td>\n",
              "      <td>9176.061</td>\n",
              "      <td>10704.678</td>\n",
              "      <td>11398.771</td>\n",
              "      <td>10360.027</td>\n",
              "      <td>11108.060</td>\n",
              "      <td>11440.514</td>\n",
              "      <td>9073.175</td>\n",
              "      <td>9461.005</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13031</th>\n",
              "      <td>1.1848</td>\n",
              "      <td>1.5638</td>\n",
              "      <td>1.4769</td>\n",
              "      <td>2.9390</td>\n",
              "      <td>3.4769</td>\n",
              "      <td>2.3142</td>\n",
              "      <td>2.5730</td>\n",
              "      <td>1.2902</td>\n",
              "      <td>1.6839</td>\n",
              "      <td>3.4455</td>\n",
              "      <td>...</td>\n",
              "      <td>262958.914</td>\n",
              "      <td>285735.507</td>\n",
              "      <td>307587.675</td>\n",
              "      <td>299389.564</td>\n",
              "      <td>316437.921</td>\n",
              "      <td>294029.876</td>\n",
              "      <td>288840.762</td>\n",
              "      <td>287647.980</td>\n",
              "      <td>303895.461</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13032</th>\n",
              "      <td>-1.1078</td>\n",
              "      <td>0.8627</td>\n",
              "      <td>0.8627</td>\n",
              "      <td>1.2255</td>\n",
              "      <td>1.7255</td>\n",
              "      <td>0.2451</td>\n",
              "      <td>1.0294</td>\n",
              "      <td>0.6765</td>\n",
              "      <td>0.3824</td>\n",
              "      <td>0.9706</td>\n",
              "      <td>...</td>\n",
              "      <td>10471.817</td>\n",
              "      <td>8660.796</td>\n",
              "      <td>10948.821</td>\n",
              "      <td>11523.082</td>\n",
              "      <td>11647.923</td>\n",
              "      <td>9441.705</td>\n",
              "      <td>9310.609</td>\n",
              "      <td>8159.080</td>\n",
              "      <td>8141.003</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13033</th>\n",
              "      <td>-1.3900</td>\n",
              "      <td>0.6900</td>\n",
              "      <td>0.4500</td>\n",
              "      <td>1.4400</td>\n",
              "      <td>1.7000</td>\n",
              "      <td>0.5700</td>\n",
              "      <td>0.8200</td>\n",
              "      <td>0.8800</td>\n",
              "      <td>0.3700</td>\n",
              "      <td>1.9300</td>\n",
              "      <td>...</td>\n",
              "      <td>10565.884</td>\n",
              "      <td>8806.434</td>\n",
              "      <td>10773.072</td>\n",
              "      <td>10456.661</td>\n",
              "      <td>11102.445</td>\n",
              "      <td>8963.299</td>\n",
              "      <td>8891.549</td>\n",
              "      <td>7769.568</td>\n",
              "      <td>7952.767</td>\n",
              "      <td>d</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13034</th>\n",
              "      <td>0.2966</td>\n",
              "      <td>0.6949</td>\n",
              "      <td>0.7288</td>\n",
              "      <td>0.8136</td>\n",
              "      <td>0.9492</td>\n",
              "      <td>0.4237</td>\n",
              "      <td>0.5000</td>\n",
              "      <td>1.5000</td>\n",
              "      <td>1.0508</td>\n",
              "      <td>0.0254</td>\n",
              "      <td>...</td>\n",
              "      <td>12158.411</td>\n",
              "      <td>14458.614</td>\n",
              "      <td>16017.375</td>\n",
              "      <td>15627.743</td>\n",
              "      <td>14401.645</td>\n",
              "      <td>13713.625</td>\n",
              "      <td>13803.527</td>\n",
              "      <td>12025.509</td>\n",
              "      <td>11144.905</td>\n",
              "      <td>b</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>5 rows × 1871 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-93e6d0fd-b503-40ca-b013-79878a5993bd')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-93e6d0fd-b503-40ca-b013-79878a5993bd button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-93e6d0fd-b503-40ca-b013-79878a5993bd');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "classModel3(df)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KVbR3U38M57B",
        "outputId": "7fba7527-93f6-4bfc-8302-1a0b8bf3210d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['d' 'd' 'd' ... 'd' 'd' 'b']\n",
            "[3 3 3 ... 3 3 1]\n",
            "[04:29:21] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.89       772\n",
            "           1       0.82      0.88      0.85       825\n",
            "           2       0.90      0.90      0.90      1293\n",
            "           3       0.79      0.75      0.77      1021\n",
            "\n",
            "    accuracy                           0.85      3911\n",
            "   macro avg       0.85      0.85      0.85      3911\n",
            "weighted avg       0.85      0.85      0.85      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 680   11   24   57]\n",
            " [  12  725   14   74]\n",
            " [  19   33 1164   77]\n",
            " [  51  111   91  768]]\n",
            "\n",
            "\n",
            "Accuracy: 0.8532344668882639\n",
            "\n",
            "\n",
            "Precision: [0.89238845 0.82386364 0.90023202 0.78688525]\n",
            "\n",
            "Recall: [0.88082902 0.87878788 0.90023202 0.75220372]\n",
            "\n",
            "F1 score: [0.88657106 0.85043988 0.90023202 0.76915373]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "\n"
      ],
      "metadata": {
        "id": "TtB9fa2bNAfL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X= df.iloc[:,:-1]\n",
        "y= df.iloc[:,-1]\n",
        "print(X)\n",
        "print(y)\n",
        "\n",
        "le = LabelEncoder()\n",
        "print(y)\n",
        "y= le.fit_transform(y) \n",
        "print(y)\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size = 0.30, random_state = 5)\n",
        "\n",
        "model = XGBClassifier(tree_method='gpu_hist',use_label_encoder=False)\n",
        "\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "print('\\nClassification report:\\n', classification_report(y_test,y_pred))\n",
        "print('Confusion matrix: \\n', confusion_matrix(y_test,y_pred))\n",
        "\n",
        "accuracy = accuracy_score(y_test,y_pred)\n",
        "#accuracy_scores.append(accuracy)\n",
        "print(\"\\n\\nAccuracy:\",accuracy_score(y_test, y_pred))\n",
        "\n",
        "print(\"\\n\\nPrecision:\",precision_score(y_test, y_pred, average=None))\n",
        "print(\"\\nRecall:\",recall_score(y_test, y_pred, average=None))\n",
        "print(\"\\nF1 score:\",f1_score(y_test, y_pred, average=None))\n",
        "\n",
        "pickle.dump(model, open(\"model2.dat\", \"wb\"))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "29plC1_JTn2T",
        "outputId": "471d346f-b720-4a94-8c10-9bfd06009ea9"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "           V1      V2      V3      V4      V5      V6      V7      V8      V9  \\\n",
            "0      0.9877  0.7669  0.7147  0.7791  2.3712  0.4663  0.5644  1.5337  1.0644   \n",
            "1      0.1183  0.4592  0.4479  0.5577  0.4423  0.2789  0.3775  0.6761  0.6141   \n",
            "2      0.6753  0.9351  1.0390  1.8442  0.5844  0.8182  1.0649  1.6623  0.9870   \n",
            "3     -0.0625  0.4167  0.7083  0.6771  0.5104  0.1042  0.3021  0.2708  0.9688   \n",
            "4      2.0909  4.2576  4.5606  5.7576  4.9848  3.6364  4.7273  4.2121  5.4242   \n",
            "...       ...     ...     ...     ...     ...     ...     ...     ...     ...   \n",
            "13030  0.3654  0.5481  0.1346  0.5385  1.2212  0.1635  0.1442  0.6058  0.5577   \n",
            "13031  1.1848  1.5638  1.4769  2.9390  3.4769  2.3142  2.5730  1.2902  1.6839   \n",
            "13032 -1.1078  0.8627  0.8627  1.2255  1.7255  0.2451  1.0294  0.6765  0.3824   \n",
            "13033 -1.3900  0.6900  0.4500  1.4400  1.7000  0.5700  0.8200  0.8800  0.3700   \n",
            "13034  0.2966  0.6949  0.7288  0.8136  0.9492  0.4237  0.5000  1.5000  1.0508   \n",
            "\n",
            "          V10  ...        V551        V552        V553        V554  \\\n",
            "0      2.1135  ...   95877.142  114070.624  108091.136  114669.085   \n",
            "1      0.2000  ...  120356.604  137325.433  131197.669  135505.009   \n",
            "2      0.0649  ...    4743.110    5949.595    5316.943    5636.386   \n",
            "3      0.3125  ...    7587.045    8391.055    8743.541    7549.078   \n",
            "4      3.4697  ...    3082.977    4683.468    4057.229    4114.765   \n",
            "...       ...  ...         ...         ...         ...         ...   \n",
            "13030  0.9712  ...    9646.457    9915.719    9176.061   10704.678   \n",
            "13031  3.4455  ...  291340.219  262958.914  285735.507  307587.675   \n",
            "13032  0.9706  ...    8200.230   10471.817    8660.796   10948.821   \n",
            "13033  1.9300  ...    7877.795   10565.884    8806.434   10773.072   \n",
            "13034  0.0254  ...   12068.708   12158.411   14458.614   16017.375   \n",
            "\n",
            "             V555        V556        V557        V558        V559        V560  \n",
            "0       99283.599  108429.814   99375.890   94187.106   96137.087  101893.312  \n",
            "1      117565.612  127873.474  123841.017  118688.798  118811.827  133332.085  \n",
            "2        5225.542    6527.143    5140.157    5661.591    5220.387    4293.378  \n",
            "3        9642.123    9897.976    8942.383    9205.542    9950.298    7470.748  \n",
            "4        3349.771    4024.599    4237.269    3284.416    3987.280    3333.758  \n",
            "...           ...         ...         ...         ...         ...         ...  \n",
            "13030   11398.771   10360.027   11108.060   11440.514    9073.175    9461.005  \n",
            "13031  299389.564  316437.921  294029.876  288840.762  287647.980  303895.461  \n",
            "13032   11523.082   11647.923    9441.705    9310.609    8159.080    8141.003  \n",
            "13033   10456.661   11102.445    8963.299    8891.549    7769.568    7952.767  \n",
            "13034   15627.743   14401.645   13713.625   13803.527   12025.509   11144.905  \n",
            "\n",
            "[13035 rows x 1870 columns]\n",
            "0        d\n",
            "1        d\n",
            "2        d\n",
            "3        d\n",
            "4        a\n",
            "        ..\n",
            "13030    b\n",
            "13031    d\n",
            "13032    d\n",
            "13033    d\n",
            "13034    b\n",
            "Name: class, Length: 13035, dtype: object\n",
            "0        d\n",
            "1        d\n",
            "2        d\n",
            "3        d\n",
            "4        a\n",
            "        ..\n",
            "13030    b\n",
            "13031    d\n",
            "13032    d\n",
            "13033    d\n",
            "13034    b\n",
            "Name: class, Length: 13035, dtype: object\n",
            "[3 3 3 ... 3 3 1]\n",
            "[04:37:48] WARNING: ../src/learner.cc:1115: Starting in XGBoost 1.3.0, the default evaluation metric used with the objective 'multi:softprob' was changed from 'merror' to 'mlogloss'. Explicitly set eval_metric if you'd like to restore the old behavior.\n",
            "\n",
            "Classification report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.88      0.89       772\n",
            "           1       0.82      0.88      0.85       825\n",
            "           2       0.90      0.90      0.90      1293\n",
            "           3       0.79      0.75      0.77      1021\n",
            "\n",
            "    accuracy                           0.85      3911\n",
            "   macro avg       0.85      0.85      0.85      3911\n",
            "weighted avg       0.85      0.85      0.85      3911\n",
            "\n",
            "Confusion matrix: \n",
            " [[ 680   11   24   57]\n",
            " [  12  725   14   74]\n",
            " [  19   33 1164   77]\n",
            " [  51  111   91  768]]\n",
            "\n",
            "\n",
            "Accuracy: 0.8532344668882639\n",
            "\n",
            "\n",
            "Precision: [0.89238845 0.82386364 0.90023202 0.78688525]\n",
            "\n",
            "Recall: [0.88082902 0.87878788 0.90023202 0.75220372]\n",
            "\n",
            "F1 score: [0.88657106 0.85043988 0.90023202 0.76915373]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ifdAIBQPT2Gt"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}